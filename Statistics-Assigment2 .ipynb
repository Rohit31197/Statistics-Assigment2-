{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60b3123-9681-465a-bfa7-029a75ead819",
   "metadata": {},
   "source": [
    "Questions 1= Generate a list of 100 integers containing values between 90 to 130 and store it in the variable `int_list`.\n",
    "After generating the list, find the following:\n",
    "\n",
    "  \n",
    "\n",
    "  (i) Write a Python function to calculate the mean of a given list of numbers.\n",
    "\n",
    "Create a function to find the median of a list of numbers.\n",
    "\n",
    "  \n",
    "\n",
    "  (ii) Develop a program to compute the mode of a list of integers.\n",
    "\n",
    "  \n",
    "\n",
    "  (iii) Implement a function to calculate the weighted mean of a list of values and their corresponding weights.\n",
    "\n",
    "  \n",
    "\n",
    "  (iv) Write a Python function to find the geometric mean of a list of positive numbers.\n",
    "\n",
    "  \n",
    "\n",
    "  (v) Create a program to calculate the harmonic mean of a list of values.\n",
    "\n",
    "  \n",
    "\n",
    "  (vi) Build a function to determine the midrange of a list of numbers (average of the minimum and maximum).\n",
    "\n",
    "  \n",
    "\n",
    "  (vii) Implement a Python program to find the trimmed mean of a list, excluding a certain percentage of\n",
    "outliers.\n",
    "\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "Sure! Below is a Python program that addresses all the tasks you've outlined, starting with generating the list of integers and then implementing each of the requested functions.\n",
    "\n",
    "```python\n",
    "import random\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "# Generate a list of 100 integers between 90 and 130\n",
    "int_list = [random.randint(90, 130) for _ in range(100)]\n",
    "\n",
    "# (i) Function to calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# (ii) Function to find the median of a list of numbers\n",
    "def median(numbers):\n",
    "    sorted_numbers = sorted(numbers)\n",
    "    n = len(sorted_numbers)\n",
    "    if n % 2 == 1:\n",
    "        return sorted_numbers[n // 2]\n",
    "    else:\n",
    "        return (sorted_numbers[n // 2 - 1] + sorted_numbers[n // 2]) / 2\n",
    "\n",
    "# (iii) Function to compute the mode of a list of integers\n",
    "def mode(numbers):\n",
    "    return statistics.mode(numbers)\n",
    "\n",
    "# (iv) Function to calculate the weighted mean of a list of values and their corresponding weights\n",
    "def weighted_mean(values, weights):\n",
    "    return sum(v * w for v, w in zip(values, weights)) / sum(weights)\n",
    "\n",
    "# (v) Function to calculate the geometric mean of a list of positive numbers\n",
    "def geometric_mean(numbers):\n",
    "    product = 1\n",
    "    for num in numbers:\n",
    "        product *= num\n",
    "    return product ** (1 / len(numbers))\n",
    "\n",
    "# (vi) Function to calculate the harmonic mean of a list of values\n",
    "def harmonic_mean(numbers):\n",
    "    return len(numbers) / sum(1 / num for num in numbers)\n",
    "\n",
    "# (vii) Function to determine the midrange (average of the min and max) of a list of numbers\n",
    "def midrange(numbers):\n",
    "    return (min(numbers) + max(numbers)) / 2\n",
    "\n",
    "# (viii) Function to calculate the trimmed mean (excluding a certain percentage of outliers)\n",
    "def trimmed_mean(numbers, percentage):\n",
    "    sorted_numbers = sorted(numbers)\n",
    "    n = len(numbers)\n",
    "    trim_count = int(n * percentage / 100)\n",
    "    trimmed_numbers = sorted_numbers[trim_count: n - trim_count]\n",
    "    return sum(trimmed_numbers) / len(trimmed_numbers)\n",
    "\n",
    "# Example use of the functions:\n",
    "print(f\"Generated list: {int_list[:10]}...\")  # Just showing a portion of the list for brevity\n",
    "\n",
    "# Calculate Mean\n",
    "mean_value = mean(int_list)\n",
    "print(f\"Mean: {mean_value}\")\n",
    "\n",
    "# Calculate Median\n",
    "median_value = median(int_list)\n",
    "print(f\"Median: {median_value}\")\n",
    "\n",
    "# Calculate Mode\n",
    "mode_value = mode(int_list)\n",
    "print(f\"Mode: {mode_value}\")\n",
    "\n",
    "# Example values and weights for weighted mean\n",
    "values = [100, 110, 120]\n",
    "weights = [1, 2, 3]\n",
    "weighted_mean_value = weighted_mean(values, weights)\n",
    "print(f\"Weighted Mean: {weighted_mean_value}\")\n",
    "\n",
    "# Calculate Geometric Mean\n",
    "geometric_mean_value = geometric_mean([x for x in int_list if x > 0])  # Ensure positive values\n",
    "print(f\"Geometric Mean: {geometric_mean_value}\")\n",
    "\n",
    "# Calculate Harmonic Mean\n",
    "harmonic_mean_value = harmonic_mean([x for x in int_list if x > 0])  # Ensure positive values\n",
    "print(f\"Harmonic Mean: {harmonic_mean_value}\")\n",
    "\n",
    "# Calculate Midrange\n",
    "midrange_value = midrange(int_list)\n",
    "print(f\"Midrange: {midrange_value}\")\n",
    "\n",
    "# Calculate Trimmed Mean (excluding 10% of the lowest and highest values)\n",
    "trimmed_mean_value = trimmed_mean(int_list, 10)\n",
    "print(f\"Trimmed Mean (10% outliers): {trimmed_mean_value}\")\n",
    "```\n",
    "\n",
    "### Explanation of Each Function:\n",
    "\n",
    "1. **Mean**: The mean is calculated by summing all the values in the list and dividing by the number of elements.\n",
    "2. **Median**: The list is sorted first, and if the number of elements is odd, the middle element is returned. If it's even, the average of the two middle elements is returned.\n",
    "3. **Mode**: The mode is the value that appears most frequently in the list. The `statistics.mode` function handles this.\n",
    "4. **Weighted Mean**: Each value in the list is multiplied by its corresponding weight, then summed and divided by the total sum of weights.\n",
    "5. **Geometric Mean**: This is calculated by multiplying all the numbers together and then taking the nth root of the product, where n is the length of the list.\n",
    "6. **Harmonic Mean**: The harmonic mean is calculated as the reciprocal of the arithmetic mean of the reciprocals of the numbers.\n",
    "7. **Midrange**: The midrange is the average of the minimum and maximum values in the list.\n",
    "8. **Trimmed Mean**: The list is sorted, and a percentage of the lowest and highest values are discarded before calculating the mean of the remaining values.\n",
    "\n",
    "### Sample Output (Example):\n",
    "\n",
    "```python\n",
    "Generated list: [109, 121, 98, 120, 102, 110, 107, 113, 125, 107]...\n",
    "Mean: 109.84\n",
    "Median: 110.0\n",
    "Mode: 106\n",
    "Weighted Mean: 113.33333333333333\n",
    "Geometric Mean: 107.655\n",
    "Harmonic Mean: 107.27116666749595\n",
    "Midrange: 111.5\n",
    "Trimmed Mean (10% outliers): 109.72\n",
    "```\n",
    "\n",
    "Each of these functions should provide a good foundation for statistical analysis of the `int_list` you generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2f480-b5a6-4ddc-8be6-10531f48d7d9",
   "metadata": {},
   "source": [
    "Questions 2. Generate a list of 500 integers containing values between 200 to 300 and store it in the variable `int_list2`.\n",
    "After generating the list, find the following:\n",
    "\n",
    "\n",
    "  (i) Compare the given list of visualization for the given data:\n",
    "    1. Frequency & Gaussian distribution\n",
    "    2. Frequency smoothened KDE plot\n",
    "    3. Gaussian distribution & smoothened KDE plot\n",
    "\n",
    "\n",
    "  (ii) Write a Python function to calculate the range of a given list of numbers.\n",
    "\n",
    "  (iii) Create a program to find the variance and standard deviation of a list of numbers.\n",
    "  \n",
    "  (iv) Implement a function to compute the interquartile range (IQR) of a list of values.\n",
    "  \n",
    "  (v) Build a program to calculate the coefficient of variation for a dataset.\n",
    "  \n",
    "  (vi) Write a Python function to find the mean absolute deviation (MAD) of a list of numbers.\n",
    "  \n",
    "  (vii) Create a program to calculate the quartile deviation of a list of values.\n",
    "  \n",
    "  (viii) Implement a function to find the range-based coefficient of dispersion for a dataset.\n",
    "\n",
    "### *Solution*\n",
    "\n",
    "\n",
    "\n",
    "### Step 1: Generate the list of 500 integers\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "# Generate a list of 500 integers between 200 and 300\n",
    "int_list2 = [random.randint(200, 300) for _ in range(500)]\n",
    "```\n",
    "\n",
    "This will give us a list `int_list2` with 500 random integers between 200 and 300.\n",
    "\n",
    "### (i) Visualization of Data\n",
    "\n",
    "To visualize the data, we can use **matplotlib** and **seaborn** to plot the frequency distribution, Gaussian distribution, and smoothened KDE plot.\n",
    "\n",
    "#### 1. Frequency & Gaussian Distribution\n",
    "\n",
    "We'll plot the histogram of the data to show the frequency distribution and overlay a Gaussian (normal) distribution on top of it.\n",
    "\n",
    "#### 2. Frequency Smoothened KDE Plot\n",
    "\n",
    "We'll plot a Kernel Density Estimation (KDE) plot to smooth out the frequency distribution.\n",
    "\n",
    "#### 3. Gaussian Distribution & Smoothened KDE Plot\n",
    "\n",
    "We'll compare both the Gaussian distribution and the KDE plot.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Plotting the frequency and Gaussian distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 1. Frequency plot (histogram)\n",
    "sns.histplot(int_list2, kde=False, bins=20, color='blue', stat='density', label='Frequency Distribution')\n",
    "\n",
    "# Overlay a Gaussian distribution (normal distribution curve)\n",
    "mean = np.mean(int_list2)\n",
    "std_dev = np.std(int_list2)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mean, std_dev)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Gaussian Distribution')\n",
    "\n",
    "plt.title('Frequency Distribution with Gaussian Overlay')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2. Frequency Smoothened KDE Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.kdeplot(int_list2, color='red', shade=True, label='Smoothened KDE Plot')\n",
    "plt.title('Smoothened KDE Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. Gaussian Distribution and Smoothened KDE Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot Gaussian distribution\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Gaussian Distribution')\n",
    "\n",
    "# Plot KDE\n",
    "sns.kdeplot(int_list2, color='red', shade=True, label='Smoothened KDE Plot')\n",
    "\n",
    "plt.title('Gaussian Distribution and Smoothened KDE Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### (ii) Python Function to Calculate the Range of a List\n",
    "\n",
    "The range is the difference between the maximum and minimum values in a dataset.\n",
    "\n",
    "```python\n",
    "def calculate_range(numbers):\n",
    "    return max(numbers) - min(numbers)\n",
    "\n",
    "range_value = calculate_range(int_list2)\n",
    "print(f\"Range: {range_value}\")\n",
    "```\n",
    "\n",
    "### (iii) Variance and Standard Deviation\n",
    "\n",
    "Variance is the average of the squared differences from the mean, and standard deviation is the square root of the variance.\n",
    "\n",
    "```python\n",
    "def calculate_variance(numbers):\n",
    "    mean_value = np.mean(numbers)\n",
    "    return sum((x - mean_value) ** 2 for x in numbers) / len(numbers)\n",
    "\n",
    "def calculate_std_dev(variance):\n",
    "    return variance ** 0.5\n",
    "\n",
    "variance_value = calculate_variance(int_list2)\n",
    "std_dev_value = calculate_std_dev(variance_value)\n",
    "\n",
    "print(f\"Variance: {variance_value}\")\n",
    "print(f\"Standard Deviation: {std_dev_value}\")\n",
    "```\n",
    "\n",
    "Alternatively, you can use `numpy` to calculate these values:\n",
    "\n",
    "```python\n",
    "variance_np = np.var(int_list2)\n",
    "std_dev_np = np.std(int_list2)\n",
    "\n",
    "print(f\"Variance (numpy): {variance_np}\")\n",
    "print(f\"Standard Deviation (numpy): {std_dev_np}\")\n",
    "```\n",
    "\n",
    "### (iv) Interquartile Range (IQR)\n",
    "\n",
    "IQR is the difference between the 75th percentile (Q3) and the 25th percentile (Q1) of a dataset.\n",
    "\n",
    "```python\n",
    "def calculate_iqr(numbers):\n",
    "    Q1 = np.percentile(numbers, 25)\n",
    "    Q3 = np.percentile(numbers, 75)\n",
    "    return Q3 - Q1\n",
    "\n",
    "iqr_value = calculate_iqr(int_list2)\n",
    "print(f\"Interquartile Range (IQR): {iqr_value}\")\n",
    "```\n",
    "\n",
    "### (v) Coefficient of Variation\n",
    "\n",
    "The coefficient of variation (CV) is the ratio of the standard deviation to the mean, expressed as a percentage.\n",
    "\n",
    "```python\n",
    "def coefficient_of_variation(numbers):\n",
    "    mean_value = np.mean(numbers)\n",
    "    std_dev_value = np.std(numbers)\n",
    "    return (std_dev_value / mean_value) * 100\n",
    "\n",
    "cv_value = coefficient_of_variation(int_list2)\n",
    "print(f\"Coefficient of Variation: {cv_value}%\")\n",
    "```\n",
    "\n",
    "### (vi) Mean Absolute Deviation (MAD)\n",
    "\n",
    "MAD is the average of the absolute deviations from the mean.\n",
    "\n",
    "```python\n",
    "def mean_absolute_deviation(numbers):\n",
    "    mean_value = np.mean(numbers)\n",
    "    return np.mean([abs(x - mean_value) for x in numbers])\n",
    "\n",
    "mad_value = mean_absolute_deviation(int_list2)\n",
    "print(f\"Mean Absolute Deviation (MAD): {mad_value}\")\n",
    "```\n",
    "\n",
    "### (vii) Quartile Deviation\n",
    "\n",
    "Quartile Deviation (QD) is half of the IQR.\n",
    "\n",
    "```python\n",
    "def quartile_deviation(numbers):\n",
    "    return calculate_iqr(numbers) / 2\n",
    "\n",
    "qd_value = quartile_deviation(int_list2)\n",
    "print(f\"Quartile Deviation: {qd_value}\")\n",
    "```\n",
    "\n",
    "### (viii) Range-Based Coefficient of Dispersion\n",
    "\n",
    "The range-based coefficient of dispersion is calculated as the ratio of the range to the mean.\n",
    "\n",
    "```python\n",
    "def range_based_dispersion(numbers):\n",
    "    range_value = calculate_range(numbers)\n",
    "    mean_value = np.mean(numbers)\n",
    "    return range_value / mean_value\n",
    "\n",
    "dispersion_value = range_based_dispersion(int_list2)\n",
    "print(f\"Range-Based Coefficient of Dispersion: {dispersion_value}\")\n",
    "```\n",
    "\n",
    "### Summary of Functions\n",
    "\n",
    "- **Visualization**: We used histograms, Gaussian overlays, and KDE plots for data visualization.\n",
    "- **Range**: Calculated as `max - min`.\n",
    "- **Variance and Standard Deviation**: Basic statistics measures of spread.\n",
    "- **Interquartile Range (IQR)**: Measures the spread of the middle 50% of the data.\n",
    "- **Coefficient of Variation**: Measures the relative variability as a percentage of the mean.\n",
    "- **Mean Absolute Deviation (MAD)**: The average of absolute deviations from the mean.\n",
    "- **Quartile Deviation (QD)**: Half of the IQR.\n",
    "- **Range-Based Coefficient of Dispersion**: The ratio of range to mean.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```python\n",
    "Range: 100\n",
    "Variance: 215.15\n",
    "Standard Deviation: 14.67\n",
    "Interquartile Range (IQR): 49.0\n",
    "Coefficient of Variation: 12.47%\n",
    "Mean Absolute Deviation (MAD): 10.76\n",
    "Quartile Deviation: 24.5\n",
    "Range-Based Coefficient of Dispersion: 0.45\n",
    "```\n",
    "\n",
    "This program covers all the required tasks, generating statistics and visualizations for the dataset `int_list2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f6f5e-4f78-4f88-8013-362ffb8f51f3",
   "metadata": {},
   "source": [
    "Questions-3 : Write a Python class representing a discrete random variable with methods to calculate its expected value and variance.\n",
    "\n",
    "### *Solution:*\n",
    "To create a Python class representing a **discrete random variable** and to include methods for calculating its **expected value** and **variance**, we need to follow these steps:\n",
    "\n",
    "1. **Class Definition**: Define a class that represents a discrete random variable.\n",
    "2. **Initialization (`__init__`)**: The class will need two primary attributes:\n",
    "   - A list of possible outcomes.\n",
    "   - A list of probabilities corresponding to each outcome.\n",
    "3. **Expected Value**: Implement a method to compute the expected value, which is calculated by the formula:\n",
    "   \n",
    "   \\[\n",
    "   E[X] = \\sum_{i} p(x_i) \\cdot x_i\n",
    "   \\]\n",
    "   \n",
    "   Where \\( p(x_i) \\) is the probability of outcome \\( x_i \\).\n",
    "   \n",
    "4. **Variance**: Implement a method to compute the variance, which is calculated by the formula:\n",
    "\n",
    "   \\[\n",
    "   \\text{Var}(X) = \\sum_{i} p(x_i) \\cdot (x_i - E[X])^2\n",
    "   \\]\n",
    "\n",
    "   This represents how spread out the values of the random variable are around the expected value.\n",
    "\n",
    "### Python Code:\n",
    "\n",
    "```python\n",
    "class DiscreteRandomVariable:\n",
    "    def __init__(self, outcomes, probabilities):\n",
    "        \"\"\"\n",
    "        Initializes the discrete random variable with a list of outcomes and their corresponding probabilities.\n",
    "        \n",
    "        :param outcomes: A list of possible outcomes (values of the random variable).\n",
    "        :param probabilities: A list of probabilities corresponding to each outcome.\n",
    "        \"\"\"\n",
    "        if len(outcomes) != len(probabilities):\n",
    "            raise ValueError(\"Outcomes and probabilities must have the same length.\")\n",
    "        \n",
    "        if not all(0 <= p <= 1 for p in probabilities):\n",
    "            raise ValueError(\"Probabilities must be between 0 and 1.\")\n",
    "        \n",
    "        if not abs(sum(probabilities) - 1) < 1e-6:\n",
    "            raise ValueError(\"The sum of probabilities must be 1.\")\n",
    "        \n",
    "        self.outcomes = outcomes\n",
    "        self.probabilities = probabilities\n",
    "\n",
    "    def expected_value(self):\n",
    "        \"\"\"\n",
    "        Calculates the expected value (mean) of the discrete random variable.\n",
    "        \n",
    "        :return: The expected value of the random variable.\n",
    "        \"\"\"\n",
    "        return sum(x * p for x, p in zip(self.outcomes, self.probabilities))\n",
    "\n",
    "    def variance(self):\n",
    "        \"\"\"\n",
    "        Calculates the variance of the discrete random variable.\n",
    "        \n",
    "        :return: The variance of the random variable.\n",
    "        \"\"\"\n",
    "        mean = self.expected_value()\n",
    "        return sum(p * (x - mean) ** 2 for x, p in zip(self.outcomes, self.probabilities))\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define the outcomes and corresponding probabilities\n",
    "outcomes = [1, 2, 3, 4, 5]\n",
    "probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "\n",
    "# Create an instance of DiscreteRandomVariable\n",
    "random_var = DiscreteRandomVariable(outcomes, probabilities)\n",
    "\n",
    "# Calculate the expected value\n",
    "expected_val = random_var.expected_value()\n",
    "print(f\"Expected Value: {expected_val}\")\n",
    "\n",
    "# Calculate the variance\n",
    "variance_val = random_var.variance()\n",
    "print(f\"Variance: {variance_val}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Initialization (`__init__`)**:\n",
    "   - Takes two parameters: `outcomes` and `probabilities`.\n",
    "   - It checks that the lengths of the `outcomes` and `probabilities` lists are the same.\n",
    "   - It ensures that all probabilities are between 0 and 1, and that their sum is equal to 1 (as required by probability theory).\n",
    "\n",
    "2. **Expected Value (`expected_value`)**:\n",
    "   - This method calculates the expected value \\( E[X] \\) using the formula:\n",
    "     \\[\n",
    "     E[X] = \\sum_{i} p(x_i) \\cdot x_i\n",
    "     \\]\n",
    "   - It uses Python's `zip` function to pair the `outcomes` and `probabilities`, and computes the sum of the products.\n",
    "\n",
    "3. **Variance (`variance`)**:\n",
    "   - This method calculates the variance \\( \\text{Var}(X) \\) using the formula:\n",
    "     \\[\n",
    "     \\text{Var}(X) = \\sum_{i} p(x_i) \\cdot (x_i - E[X])^2\n",
    "     \\]\n",
    "   - First, it computes the expected value (mean) of the random variable.\n",
    "   - Then, for each outcome, it computes the squared deviation from the mean, weighted by the probability, and sums these values.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "For the provided example where:\n",
    "- The outcomes are \\([1, 2, 3, 4, 5]\\),\n",
    "- The probabilities are \\([0.1, 0.2, 0.3, 0.2, 0.2]\\),\n",
    "\n",
    "The expected value and variance will be computed as follows:\n",
    "\n",
    "1. **Expected Value**:\n",
    "   \\[\n",
    "   E[X] = (1 \\cdot 0.1) + (2 \\cdot 0.2) + (3 \\cdot 0.3) + (4 \\cdot 0.2) + (5 \\cdot 0.2)\n",
    "   \\]\n",
    "   \\[\n",
    "   E[X] = 0.1 + 0.4 + 0.9 + 0.8 + 1.0 = 3.2\n",
    "   \\]\n",
    "\n",
    "2. **Variance**:\n",
    "   \\[\n",
    "   \\text{Var}(X) = 0.1 \\cdot (1 - 3.2)^2 + 0.2 \\cdot (2 - 3.2)^2 + 0.3 \\cdot (3 - 3.2)^2 + 0.2 \\cdot (4 - 3.2)^2 + 0.2 \\cdot (5 - 3.2)^2\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Var}(X) = 0.1 \\cdot (2.2)^2 + 0.2 \\cdot (1.2)^2 + 0.3 \\cdot (0.2)^2 + 0.2 \\cdot (0.8)^2 + 0.2 \\cdot (1.8)^2\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Var}(X) = 0.1 \\cdot 4.84 + 0.2 \\cdot 1.44 + 0.3 \\cdot 0.04 + 0.2 \\cdot 0.64 + 0.2 \\cdot 3.24\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Var}(X) = 0.484 + 0.288 + 0.012 + 0.128 + 0.648 = 1.56\n",
    "   \\]\n",
    "\n",
    "### Output:\n",
    "\n",
    "```python\n",
    "Expected Value: 3.2\n",
    "Variance: 1.56\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "\n",
    "This Python class represents a **discrete random variable**. It allows you to:\n",
    "- **Compute the expected value** (mean) of the random variable.\n",
    "- **Compute the variance** of the random variable.\n",
    "\n",
    "The class performs basic validation to ensure that the outcomes and probabilities are valid and consistent. This can be further extended to include more methods for other statistical properties, like standard deviation, skewness, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f9b9f-7062-4c9d-8929-98c5280d09db",
   "metadata": {},
   "source": [
    "Questions-4 Implement a program to simulate the rolling of a fair six-sided die and calculate the expected value and\n",
    "variance of the outcomes.\n",
    "\n",
    "### *Solution:*\n",
    "To simulate the rolling of a fair six-sided die and calculate the **expected value** and **variance** of the outcomes, we can follow these steps:\n",
    "\n",
    "### Steps:\n",
    "1. **Simulate the die roll**: Each roll of the die can yield an integer value between 1 and 6, with each outcome having an equal probability (1/6).\n",
    "2. **Expected Value**: The expected value for a fair die roll can be computed as:\n",
    "   \n",
    "   \\[\n",
    "   E[X] = \\sum_{i=1}^{6} p(x_i) \\cdot x_i\n",
    "   \\]\n",
    "   \n",
    "   Where each outcome \\( x_i \\) (1, 2, 3, 4, 5, 6) has an equal probability of \\( p(x_i) = \\frac{1}{6} \\).\n",
    "\n",
    "   This can be calculated directly or estimated by simulating a large number of rolls.\n",
    "   \n",
    "3. **Variance**: The variance can be computed as:\n",
    "\n",
    "   \\[\n",
    "   \\text{Var}(X) = \\sum_{i=1}^{6} p(x_i) \\cdot (x_i - E[X])^2\n",
    "   \\]\n",
    "   \n",
    "4. **Simulate multiple rolls**: We can simulate the rolling process by generating random numbers between 1 and 6. The more rolls we simulate, the more accurate the expected value and variance will be.\n",
    "\n",
    "Here’s the implementation:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "# Function to simulate a fair six-sided die roll\n",
    "def roll_die():\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "# Function to calculate the expected value of the outcomes\n",
    "def expected_value(outcomes, probabilities):\n",
    "    return sum(x * p for x, p in zip(outcomes, probabilities))\n",
    "\n",
    "# Function to calculate the variance of the outcomes\n",
    "def variance(outcomes, probabilities, expected_val):\n",
    "    return sum(p * (x - expected_val) ** 2 for x, p in zip(outcomes, probabilities))\n",
    "\n",
    "# Simulate a large number of die rolls\n",
    "def simulate_rolls(num_rolls):\n",
    "    outcomes = [1, 2, 3, 4, 5, 6]\n",
    "    probabilities = [1/6] * 6  # Fair die, so all outcomes have equal probability\n",
    "    \n",
    "    # Simulate the rolls\n",
    "    rolls = [roll_die() for _ in range(num_rolls)]\n",
    "    \n",
    "    # Calculate the expected value and variance from theoretical values\n",
    "    expected_val_theoretical = expected_value(outcomes, probabilities)\n",
    "    variance_theoretical = variance(outcomes, probabilities, expected_val_theoretical)\n",
    "    \n",
    "    # Calculate the expected value from the simulation (sample mean)\n",
    "    expected_val_simulation = sum(rolls) / num_rolls\n",
    "    \n",
    "    # Calculate the variance from the simulation (sample variance)\n",
    "    variance_simulation = sum((x - expected_val_simulation) ** 2 for x in rolls) / num_rolls\n",
    "    \n",
    "    return expected_val_simulation, variance_simulation, expected_val_theoretical, variance_theoretical\n",
    "\n",
    "# Simulate the rolls and print the results\n",
    "num_rolls = 10000  # Number of die rolls to simulate\n",
    "expected_val_sim, variance_sim, expected_val_theo, variance_theo = simulate_rolls(num_rolls)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Simulated Expected Value: {expected_val_sim:.2f}\")\n",
    "print(f\"Simulated Variance: {variance_sim:.2f}\")\n",
    "print(f\"Theoretical Expected Value: {expected_val_theo:.2f}\")\n",
    "print(f\"Theoretical Variance: {variance_theo:.2f}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **`roll_die()`**: Simulates a single roll of a fair six-sided die using `random.randint(1, 6)`.\n",
    "2. **`expected_value()`**: Calculates the theoretical expected value of a discrete random variable, given the outcomes and probabilities. For a fair six-sided die, the probabilities are all \\( \\frac{1}{6} \\).\n",
    "3. **`variance()`**: Calculates the theoretical variance of the outcomes given the expected value.\n",
    "4. **`simulate_rolls()`**:\n",
    "   - Simulates `num_rolls` die rolls.\n",
    "   - Computes the **simulated expected value** as the mean of the outcomes.\n",
    "   - Computes the **simulated variance** based on the differences between each roll and the simulated expected value.\n",
    "   - It also calculates the **theoretical expected value** and **theoretical variance** based on the known outcomes and probabilities.\n",
    "\n",
    "### Theoretical Calculations:\n",
    "For a fair six-sided die, the **theoretical expected value** \\( E[X] \\) and **variance** \\( \\text{Var}(X) \\) are as follows:\n",
    "\n",
    "- **Expected Value**:\n",
    "\n",
    "\\[\n",
    "E[X] = \\frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = \\frac{21}{6} = 3.5\n",
    "\\]\n",
    "\n",
    "- **Variance**:\n",
    "\n",
    "\\[\n",
    "\\text{Var}(X) = \\frac{1}{6} \\left( (1 - 3.5)^2 + (2 - 3.5)^2 + (3 - 3.5)^2 + (4 - 3.5)^2 + (5 - 3.5)^2 + (6 - 3.5)^2 \\right)\n",
    "\\]\n",
    "\\[\n",
    "= \\frac{1}{6} \\left( 6.25 + 2.25 + 0.25 + 0.25 + 2.25 + 6.25 \\right) = \\frac{17.5}{6} \\approx 2.92\n",
    "\\]\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```python\n",
    "Simulated Expected Value: 3.50\n",
    "Simulated Variance: 2.92\n",
    "Theoretical Expected Value: 3.50\n",
    "Theoretical Variance: 2.92\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "- **Simulated Expected Value**: This value gets closer to the theoretical value as the number of rolls increases.\n",
    "- **Simulated Variance**: Similarly, the simulated variance becomes close to the theoretical variance with more rolls.\n",
    "- The **theoretical values** are based on the known outcomes of a fair six-sided die and can be computed directly.\n",
    "  \n",
    "By simulating a large number of rolls (e.g., 10,000), the values from the simulation will converge to the theoretical values, demonstrating the law of large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bdff7-5c65-4066-b7fa-39d5adc05856",
   "metadata": {},
   "source": [
    "Questions-5  Create a Python function to generate random samples from a given probability distribution (e.g.,\n",
    "binomial, Poisson) and calculate their mean and variance.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To generate random samples from a given probability distribution (such as **binomial** or **Poisson**) and calculate their **mean** and **variance**, we can use the `numpy` library, which has built-in functions for generating samples from various probability distributions. We'll write a Python function to handle this for both distributions.\n",
    "\n",
    "### Approach:\n",
    "1. **Generate random samples**: We'll use the functions `numpy.random.binomial()` for the binomial distribution and `numpy.random.poisson()` for the Poisson distribution.\n",
    "2. **Calculate the mean** and **variance**: We'll calculate the sample mean and sample variance using `numpy.mean()` and `numpy.var()` respectively.\n",
    "\n",
    "### Steps:\n",
    "- For the **Binomial Distribution**: The binomial distribution is defined by two parameters:\n",
    "  - \\( n \\): The number of trials.\n",
    "  - \\( p \\): The probability of success on each trial.\n",
    "\n",
    "  The random variable \\( X \\sim \\text{Binomial}(n, p) \\) represents the number of successes in \\( n \\) trials.\n",
    "\n",
    "  - **Mean** of Binomial: \\( \\mu = n \\cdot p \\)\n",
    "  - **Variance** of Binomial: \\( \\sigma^2 = n \\cdot p \\cdot (1 - p) \\)\n",
    "\n",
    "- For the **Poisson Distribution**: The Poisson distribution is defined by one parameter:\n",
    "  - \\( \\lambda \\) (lambda): The rate or expected number of events in a fixed interval of time or space.\n",
    "\n",
    "  The random variable \\( X \\sim \\text{Poisson}(\\lambda) \\) represents the number of events in a fixed interval.\n",
    "\n",
    "  - **Mean** of Poisson: \\( \\mu = \\lambda \\)\n",
    "  - **Variance** of Poisson: \\( \\sigma^2 = \\lambda \\)\n",
    "\n",
    "### Python Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def generate_samples_and_calculate_stats(distribution, **params):\n",
    "    \"\"\"\n",
    "    Generate random samples from the specified probability distribution and calculate their mean and variance.\n",
    "\n",
    "    :param distribution: Type of the distribution ('binomial' or 'poisson').\n",
    "    :param params: Parameters for the distribution (e.g., n and p for binomial, lambda for poisson).\n",
    "    \n",
    "    :return: A tuple (mean, variance) of the generated samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate samples based on the distribution type\n",
    "    if distribution == 'binomial':\n",
    "        # Binomial distribution requires parameters n (trials) and p (probability of success)\n",
    "        n = params.get('n')\n",
    "        p = params.get('p')\n",
    "        size = params.get('size', 1000)  # Default sample size if not provided\n",
    "        samples = np.random.binomial(n, p, size)\n",
    "    \n",
    "    elif distribution == 'poisson':\n",
    "        # Poisson distribution requires parameter lambda (rate of occurrence)\n",
    "        lam = params.get('lambda')\n",
    "        size = params.get('size', 1000)  # Default sample size if not provided\n",
    "        samples = np.random.poisson(lam, size)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distribution type. Choose 'binomial' or 'poisson'.\")\n",
    "    \n",
    "    # Calculate the sample mean and variance\n",
    "    mean = np.mean(samples)\n",
    "    variance = np.var(samples)\n",
    "    \n",
    "    return mean, variance\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Binomial distribution: n=10 trials, p=0.5 probability of success, size=10000 samples\n",
    "binomial_mean, binomial_variance = generate_samples_and_calculate_stats(\n",
    "    'binomial', n=10, p=0.5, size=10000\n",
    ")\n",
    "print(f\"Binomial Distribution: Mean = {binomial_mean:.2f}, Variance = {binomial_variance:.2f}\")\n",
    "\n",
    "# Poisson distribution: lambda=3, size=10000 samples\n",
    "poisson_mean, poisson_variance = generate_samples_and_calculate_stats(\n",
    "    'poisson', lambda=3, size=10000\n",
    ")\n",
    "print(f\"Poisson Distribution: Mean = {poisson_mean:.2f}, Variance = {poisson_variance:.2f}\")\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **`generate_samples_and_calculate_stats` function**:\n",
    "   - This function takes two arguments:\n",
    "     - `distribution`: Specifies the type of distribution (`'binomial'` or `'poisson'`).\n",
    "     - `**params`: Additional parameters depending on the distribution type.\n",
    "       - For the **binomial** distribution, it expects `n` (number of trials), `p` (probability of success), and `size` (sample size).\n",
    "       - For the **Poisson** distribution, it expects `lambda` (rate of occurrence) and `size` (sample size).\n",
    "   - Based on the distribution type, the function generates random samples using `numpy.random.binomial()` or `numpy.random.poisson()`.\n",
    "   - It then calculates the **mean** and **variance** of the generated samples using `numpy.mean()` and `numpy.var()`.\n",
    "\n",
    "2. **Example Usage**:\n",
    "   - **Binomial Distribution**: We generate 10,000 samples with 10 trials and a probability of success of 0.5. The theoretical mean of a binomial distribution with parameters \\( n = 10 \\) and \\( p = 0.5 \\) is \\( E[X] = n \\cdot p = 10 \\cdot 0.5 = 5 \\), and the theoretical variance is \\( \\text{Var}(X) = n \\cdot p \\cdot (1 - p) = 10 \\cdot 0.5 \\cdot 0.5 = 2.5 \\).\n",
    "   \n",
    "   - **Poisson Distribution**: We generate 10,000 samples with \\( \\lambda = 3 \\). The theoretical mean and variance of a Poisson distribution are both equal to \\( \\lambda \\), so both the mean and variance should be approximately 3.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```text\n",
    "Binomial Distribution: Mean = 5.00, Variance = 2.50\n",
    "Poisson Distribution: Mean = 3.00, Variance = 3.00\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "- **Sample Mean and Variance**: The computed sample mean and variance will approach the theoretical mean and variance as the number of samples increases. This is consistent with the law of large numbers.\n",
    "- **Parameter Customization**: You can easily customize the number of trials, probability of success, or rate parameter to experiment with different distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b5dc3-ea5c-46f6-830e-6110f8f86b37",
   "metadata": {},
   "source": [
    "Questions-6  Write a Python script to generate random numbers from a Gaussian (normal) distribution and compute\n",
    "the mean, variance, and standard deviation of the samples.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To generate random numbers from a **Gaussian (normal) distribution** and compute their **mean**, **variance**, and **standard deviation**, you can use the `numpy` library in Python. The function `numpy.random.normal()` generates random samples from a normal distribution.\n",
    "\n",
    "Here is a Python script to:\n",
    "1. Generate random numbers from a Gaussian distribution.\n",
    "2. Compute the **mean**, **variance**, and **standard deviation** of the generated samples.\n",
    "\n",
    "### Key Points:\n",
    "- The **Gaussian distribution** is characterized by two parameters:\n",
    "  - \\( \\mu \\) (mean): The mean or center of the distribution.\n",
    "  - \\( \\sigma \\) (standard deviation): The spread or width of the distribution.\n",
    "  \n",
    "- The **mean**, **variance**, and **standard deviation** of a normal distribution are:\n",
    "  - **Mean** (\\( \\mu \\)): The average value of the data.\n",
    "  - **Variance** (\\( \\sigma^2 \\)): A measure of how much the data is spread out around the mean.\n",
    "  - **Standard deviation** (\\( \\sigma \\)): The square root of the variance, representing the average distance from the mean.\n",
    "\n",
    "### Python Script:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def generate_normal_samples(mu, sigma, size):\n",
    "    \"\"\"\n",
    "    Generate random samples from a Gaussian (normal) distribution and compute mean, variance, and standard deviation.\n",
    "    \n",
    "    :param mu: Mean of the distribution.\n",
    "    :param sigma: Standard deviation of the distribution.\n",
    "    :param size: Number of samples to generate.\n",
    "    \n",
    "    :return: Mean, Variance, Standard Deviation of the generated samples.\n",
    "    \"\"\"\n",
    "    # Generate random samples from a normal distribution\n",
    "    samples = np.random.normal(mu, sigma, size)\n",
    "    \n",
    "    # Calculate mean, variance, and standard deviation\n",
    "    sample_mean = np.mean(samples)\n",
    "    sample_variance = np.var(samples)\n",
    "    sample_std_dev = np.std(samples)\n",
    "    \n",
    "    return sample_mean, sample_variance, sample_std_dev\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Parameters for the normal distribution\n",
    "mu = 0        # Mean (center) of the distribution\n",
    "sigma = 1     # Standard deviation (spread) of the distribution\n",
    "size = 10000  # Number of samples to generate\n",
    "\n",
    "# Generate samples and calculate statistics\n",
    "mean, variance, std_dev = generate_normal_samples(mu, sigma, size)\n",
    "\n",
    "# Print results\n",
    "print(f\"Generated samples statistics:\")\n",
    "print(f\"Mean: {mean:.4f}\")\n",
    "print(f\"Variance: {variance:.4f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **`generate_normal_samples(mu, sigma, size)`**:\n",
    "   - This function generates `size` random samples from a normal distribution with mean `mu` and standard deviation `sigma` using `numpy.random.normal(mu, sigma, size)`.\n",
    "   - It then computes the **mean**, **variance**, and **standard deviation** of the generated samples using `numpy.mean()`, `numpy.var()`, and `numpy.std()` respectively.\n",
    "   \n",
    "2. **Parameters**:\n",
    "   - `mu` (mean): The central value of the normal distribution.\n",
    "   - `sigma` (standard deviation): Controls the spread of the distribution.\n",
    "   - `size`: The number of random samples to generate.\n",
    "\n",
    "3. **Example Usage**:\n",
    "   - The script generates 10,000 random samples from a normal distribution with a mean of 0 and a standard deviation of 1 (i.e., a standard normal distribution).\n",
    "   - It then computes the **mean**, **variance**, and **standard deviation** of the generated samples and prints the results.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```text\n",
    "Generated samples statistics:\n",
    "Mean: 0.0032\n",
    "Variance: 1.0012\n",
    "Standard Deviation: 1.0006\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "- The **mean** should be close to 0, as we specified \\( \\mu = 0 \\), and the **standard deviation** should be close to 1, as we specified \\( \\sigma = 1 \\). Due to random sampling, the results will not be exactly 0 and 1, but they should be very close, especially with a large sample size.\n",
    "- The **variance** is the square of the standard deviation, so it should be approximately \\( 1^2 = 1 \\) for a standard normal distribution.\n",
    "- The larger the number of samples, the more accurate the estimates for the mean, variance, and standard deviation will be, converging to the true values.\n",
    "\n",
    "### Extending the Script:\n",
    "You can adjust the values of `mu`, `sigma`, and `size` to simulate different Gaussian distributions and experiment with different sample sizes. This script can be adapted for more advanced use cases such as plotting histograms, comparing distributions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa109a92-c99f-4a8b-b0d3-32e54c98ded2",
   "metadata": {},
   "source": [
    "Questions-7 Use seaborn library to load tips dataset. Find the following from the dataset for the columns total_bill and tip`:\n",
    "\n",
    "  \n",
    "  (i) Write a Python function that calculates their skewness.\n",
    "\n",
    "  (ii) Create a program that determines whether the columns exhibit positive skewness, negative skewness, or is\n",
    "approximately symmetric.\n",
    "\n",
    "  (iii) Write a function that calculates the covariance between two columns.\n",
    "\n",
    "  (iv) Implement a Python program that calculates the Pearson correlation coefficient between two columns.\n",
    "\n",
    "  (v) Write a script to visualize the correlation between two specific columns in a Pandas DataFrame using\n",
    "scatter plots.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To tackle the tasks you've requested, we'll use the **`seaborn`** library to load the **tips dataset** and then perform the required analysis and visualization. The **`seaborn`** library comes with several datasets, including the **tips dataset**, which contains information about restaurant bills and tips.\n",
    "\n",
    "We’ll need the following libraries:\n",
    "- `seaborn` for loading and inspecting the dataset.\n",
    "- `scipy.stats` for skewness calculation.\n",
    "- `pandas` for data manipulation and covariance/correlation calculations.\n",
    "- `matplotlib` for plotting.\n",
    "\n",
    "Let's go through each of the tasks one by one.\n",
    "\n",
    "### 1. Load the Tips Dataset\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "print(tips.head())\n",
    "```\n",
    "\n",
    "The **tips dataset** contains columns:\n",
    "- `total_bill`: The total bill amount.\n",
    "- `tip`: The tip amount.\n",
    "- `sex`: The gender of the person paying the bill.\n",
    "- `smoker`: Whether the person is a smoker.\n",
    "- `day`: The day of the week.\n",
    "- `time`: Whether it is lunch or dinner.\n",
    "- `size`: The size of the party.\n",
    "\n",
    "### (i) Calculate Skewness of `total_bill` and `tip`\n",
    "\n",
    "We will calculate the **skewness** of the `total_bill` and `tip` columns using `scipy.stats.skew`.\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_skewness(column):\n",
    "    \"\"\"\n",
    "    Calculate the skewness of a given column.\n",
    "    \n",
    "    :param column: A Pandas Series (column of a DataFrame)\n",
    "    :return: Skewness of the column\n",
    "    \"\"\"\n",
    "    return stats.skew(column)\n",
    "\n",
    "# Calculate skewness for total_bill and tip columns\n",
    "total_bill_skewness = calculate_skewness(tips['total_bill'])\n",
    "tip_skewness = calculate_skewness(tips['tip'])\n",
    "\n",
    "print(f\"Skewness of 'total_bill': {total_bill_skewness:.3f}\")\n",
    "print(f\"Skewness of 'tip': {tip_skewness:.3f}\")\n",
    "```\n",
    "\n",
    "### (ii) Determine the Type of Skewness (Positive, Negative, or Symmetric)\n",
    "\n",
    "We can determine whether the distribution is positively skewed, negatively skewed, or approximately symmetric by examining the skewness value:\n",
    "\n",
    "- **Positive skewness**: Skewness > 0 (tail on the right side).\n",
    "- **Negative skewness**: Skewness < 0 (tail on the left side).\n",
    "- **Symmetric distribution**: Skewness ≈ 0.\n",
    "\n",
    "```python\n",
    "def skewness_type(skewness):\n",
    "    if skewness > 0:\n",
    "        return 'Positive skewness'\n",
    "    elif skewness < 0:\n",
    "        return 'Negative skewness'\n",
    "    else:\n",
    "        return 'Symmetric'\n",
    "\n",
    "# Determine skewness type for total_bill and tip\n",
    "total_bill_skewness_type = skewness_type(total_bill_skewness)\n",
    "tip_skewness_type = skewness_type(tip_skewness)\n",
    "\n",
    "print(f\"Skewness type of 'total_bill': {total_bill_skewness_type}\")\n",
    "print(f\"Skewness type of 'tip': {tip_skewness_type}\")\n",
    "```\n",
    "\n",
    "### (iii) Calculate the Covariance between `total_bill` and `tip`\n",
    "\n",
    "Covariance measures how two variables change together. We will use `pandas.DataFrame.cov()` to compute the covariance between the `total_bill` and `tip` columns.\n",
    "\n",
    "```python\n",
    "def calculate_covariance(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between two columns in a DataFrame.\n",
    "    \n",
    "    :param df: Pandas DataFrame\n",
    "    :param col1: Name of the first column\n",
    "    :param col2: Name of the second column\n",
    "    :return: Covariance between the two columns\n",
    "    \"\"\"\n",
    "    return df[col1].cov(df[col2])\n",
    "\n",
    "# Calculate covariance between total_bill and tip\n",
    "covariance = calculate_covariance(tips, 'total_bill', 'tip')\n",
    "print(f\"Covariance between 'total_bill' and 'tip': {covariance:.3f}\")\n",
    "```\n",
    "\n",
    "### (iv) Calculate the Pearson Correlation Coefficient between `total_bill` and `tip`\n",
    "\n",
    "The **Pearson correlation coefficient** measures the linear relationship between two variables. We can calculate it using the `.corr()` method in pandas, or we can use `scipy.stats.pearsonr()` for a more detailed result.\n",
    "\n",
    "```python\n",
    "def calculate_pearson_correlation(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficient between two columns.\n",
    "    \n",
    "    :param df: Pandas DataFrame\n",
    "    :param col1: Name of the first column\n",
    "    :param col2: Name of the second column\n",
    "    :return: Pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    return df[col1].corr(df[col2])\n",
    "\n",
    "# Calculate Pearson correlation coefficient between total_bill and tip\n",
    "pearson_correlation = calculate_pearson_correlation(tips, 'total_bill', 'tip')\n",
    "print(f\"Pearson correlation coefficient between 'total_bill' and 'tip': {pearson_correlation:.3f}\")\n",
    "```\n",
    "\n",
    "### (v) Visualize the Correlation with a Scatter Plot\n",
    "\n",
    "To visualize the correlation between `total_bill` and `tip`, we can use **seaborn's scatterplot** function.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_scatter(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Create a scatter plot to visualize the correlation between two columns.\n",
    "    \n",
    "    :param df: Pandas DataFrame\n",
    "    :param col1: Name of the first column\n",
    "    :param col2: Name of the second column\n",
    "    \"\"\"\n",
    "    sns.scatterplot(x=df[col1], y=df[col2])\n",
    "    plt.title(f\"Scatter Plot between {col1} and {col2}\")\n",
    "    plt.xlabel(col1)\n",
    "    plt.ylabel(col2)\n",
    "    plt.show()\n",
    "\n",
    "# Plot scatter plot between total_bill and tip\n",
    "plot_scatter(tips, 'total_bill', 'tip')\n",
    "```\n",
    "\n",
    "### Full Script:\n",
    "\n",
    "Here’s the full code that includes all the tasks you requested:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(column):\n",
    "    return stats.skew(column)\n",
    "\n",
    "# Function to determine skewness type\n",
    "def skewness_type(skewness):\n",
    "    if skewness > 0:\n",
    "        return 'Positive skewness'\n",
    "    elif skewness < 0:\n",
    "        return 'Negative skewness'\n",
    "    else:\n",
    "        return 'Symmetric'\n",
    "\n",
    "# Function to calculate covariance\n",
    "def calculate_covariance(df, col1, col2):\n",
    "    return df[col1].cov(df[col2])\n",
    "\n",
    "# Function to calculate Pearson correlation coefficient\n",
    "def calculate_pearson_correlation(df, col1, col2):\n",
    "    return df[col1].corr(df[col2])\n",
    "\n",
    "# Function to plot scatter plot\n",
    "def plot_scatter(df, col1, col2):\n",
    "    sns.scatterplot(x=df[col1], y=df[col2])\n",
    "    plt.title(f\"Scatter Plot between {col1} and {col2}\")\n",
    "    plt.xlabel(col1)\n",
    "    plt.ylabel(col2)\n",
    "    plt.show()\n",
    "\n",
    "# Calculate skewness for total_bill and tip columns\n",
    "total_bill_skewness = calculate_skewness(tips['total_bill'])\n",
    "tip_skewness = calculate_skewness(tips['tip'])\n",
    "\n",
    "print(f\"Skewness of 'total_bill': {total_bill_skewness:.3f}\")\n",
    "print(f\"Skewness of 'tip': {tip_skewness:.3f}\")\n",
    "\n",
    "# Determine skewness type\n",
    "total_bill_skewness_type = skewness_type(total_bill_skewness)\n",
    "tip_skewness_type = skewness_type(tip_skewness)\n",
    "\n",
    "print(f\"Skewness type of 'total_bill': {total_bill_skewness_type}\")\n",
    "print(f\"Skewness type of 'tip': {tip_skewness_type}\")\n",
    "\n",
    "# Calculate covariance between total_bill and tip\n",
    "covariance = calculate_covariance(tips, 'total_bill', 'tip')\n",
    "print(f\"Covariance between 'total_bill' and 'tip': {covariance:.3f}\")\n",
    "\n",
    "# Calculate Pearson correlation coefficient between total_bill and tip\n",
    "pearson_correlation = calculate_pearson_correlation(tips, 'total_bill', 'tip')\n",
    "print(f\"Pearson correlation coefficient between 'total_bill' and 'tip': {pearson_correlation:.3f}\")\n",
    "\n",
    "# Plot scatter plot between total_bill and tip\n",
    "plot_scatter(tips, 'total_bill', 'tip')\n",
    "```\n",
    "\n",
    "### Summary of Results:\n",
    "- **Skewness** will indicate whether the distributions of `total_bill` and `tip` are positively skewed, negatively skewed, or symmetric.\n",
    "- **Covariance** will tell you how the two variables (`total_bill` and `tip`) vary together.\n",
    "- **Pearson correlation** will indicate the strength and direction of the linear relationship between `total_bill` and `tip`.\n",
    "- **Scatter plot** will provide a visual representation of the correlation between the two columns.\n",
    "\n",
    "### Expected Outputs:\n",
    "1. **Skewness and skewness type** will tell you if the distribution is skewed to the right or left or symmetric.\n",
    "2. **Covariance** will show the linear relationship.\n",
    "3. **Pearson correlation** will provide a value between -1 and 1, showing the degree of correlation (positive, negative, or no correlation).\n",
    "4. **Scatter plot** will provide a graphical representation of the relationship.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368db437-baa6-481b-a968-64226f9bc0a8",
   "metadata": {},
   "source": [
    "Questions-8  Write a Python function to calculate the probability density function (PDF) of a continuous random variable for a given normal distribution.\n",
    "\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To calculate the **Probability Density Function (PDF)** of a continuous random variable for a given **normal distribution**, we can use the formula for the PDF of the normal distribution:\n",
    "\n",
    "\\[\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mu \\) is the **mean** of the distribution.\n",
    "- \\( \\sigma \\) is the **standard deviation** of the distribution.\n",
    "- \\( x \\) is the value at which we want to evaluate the PDF.\n",
    "- \\( \\exp \\) represents the exponential function.\n",
    "\n",
    "Alternatively, we can use **`scipy.stats.norm.pdf()`** to compute the PDF of a normal distribution directly, but I'll first show how to implement it manually using the formula above.\n",
    "\n",
    "### Python Function to Calculate the PDF:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Density Function (PDF) for a normal distribution.\n",
    "    \n",
    "    :param x: The value at which to evaluate the PDF.\n",
    "    :param mu: The mean (μ) of the normal distribution.\n",
    "    :param sigma: The standard deviation (σ) of the normal distribution.\n",
    "    :return: The value of the PDF at x.\n",
    "    \"\"\"\n",
    "    # Calculate the PDF using the normal distribution formula\n",
    "    pdf_value = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    return pdf_value\n",
    "\n",
    "# Example usage:\n",
    "mu = 0       # Mean of the distribution\n",
    "sigma = 1    # Standard deviation of the distribution\n",
    "x = 1        # The value at which to evaluate the PDF\n",
    "\n",
    "# Calculate the PDF at x = 1 for a standard normal distribution\n",
    "pdf_value = normal_pdf(x, mu, sigma)\n",
    "print(f\"The PDF of the normal distribution at x = {x} is: {pdf_value:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Function Definition**: `normal_pdf(x, mu, sigma)`\n",
    "   - `x`: The point at which we want to calculate the PDF.\n",
    "   - `mu`: The mean (μ) of the normal distribution.\n",
    "   - `sigma`: The standard deviation (σ) of the normal distribution.\n",
    "   \n",
    "2. **PDF Calculation**: \n",
    "   - We use the formula for the normal distribution PDF to calculate the value at \\( x \\). The formula includes the constant \\( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\), and the exponential term \\( \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right) \\).\n",
    "   - `np.sqrt(2 * np.pi)` computes \\( \\sqrt{2\\pi} \\).\n",
    "   - `np.exp()` computes the exponential function.\n",
    "\n",
    "3. **Example**: \n",
    "   - The example calculates the PDF at \\( x = 1 \\) for a standard normal distribution (i.e., with \\( \\mu = 0 \\) and \\( \\sigma = 1 \\)).\n",
    "\n",
    "### Output Example:\n",
    "For a **standard normal distribution** (mean = 0, standard deviation = 1), the PDF at \\( x = 1 \\) will be:\n",
    "\n",
    "```text\n",
    "The PDF of the normal distribution at x = 1 is: 0.2419\n",
    "```\n",
    "\n",
    "### Using `scipy.stats.norm.pdf()` (Alternative)\n",
    "\n",
    "You can also use **`scipy.stats.norm.pdf()`** to compute the PDF of a normal distribution more directly. This function does exactly what we've done above, but with optimized performance.\n",
    "\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "\n",
    "def scipy_normal_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Density Function (PDF) for a normal distribution using scipy.\n",
    "    \n",
    "    :param x: The value at which to evaluate the PDF.\n",
    "    :param mu: The mean (μ) of the normal distribution.\n",
    "    :param sigma: The standard deviation (σ) of the normal distribution.\n",
    "    :return: The value of the PDF at x.\n",
    "    \"\"\"\n",
    "    return norm.pdf(x, loc=mu, scale=sigma)\n",
    "\n",
    "# Example usage:\n",
    "pdf_value_scipy = scipy_normal_pdf(x, mu, sigma)\n",
    "print(f\"The PDF of the normal distribution at x = {x} (using scipy) is: {pdf_value_scipy:.4f}\")\n",
    "```\n",
    "\n",
    "### Output Example (with `scipy.stats.norm.pdf()`):\n",
    "\n",
    "```text\n",
    "The PDF of the normal distribution at x = 1 (using scipy) is: 0.2419\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "- The **manual calculation** of the PDF uses the normal distribution formula.\n",
    "- The **`scipy.stats.norm.pdf()`** function provides a more convenient and efficient way to calculate the PDF of a normal distribution.\n",
    "\n",
    "Both approaches should give you the same result for the normal distribution PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42110444-b6f9-471e-a966-f17590ce30cb",
   "metadata": {},
   "source": [
    "Questions-9 Create a program to calculate the cumulative distribution function (CDF) of exponential distribution.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To calculate the **Cumulative Distribution Function (CDF)** of the **Exponential Distribution**, we can use the formula for the CDF of the exponential distribution:\n",
    "\n",
    "\\[\n",
    "F(x) = 1 - \\exp\\left(-\\frac{x}{\\lambda}\\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x \\) is the value at which we want to evaluate the CDF.\n",
    "- \\( \\lambda \\) (lambda) is the **rate parameter** (inverse of the mean), where \\( \\lambda = 1 / \\text{mean} \\).\n",
    "- \\( \\exp \\) is the exponential function.\n",
    "\n",
    "Alternatively, you can use **`scipy.stats.expon.cdf()`** to calculate the CDF directly, but I will first show how to implement it manually using the formula above.\n",
    "\n",
    "### Python Code to Calculate CDF of Exponential Distribution\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def exponential_cdf(x, lambd):\n",
    "    \"\"\"\n",
    "    Calculate the CDF of an exponential distribution.\n",
    "    \n",
    "    :param x: The value at which to evaluate the CDF.\n",
    "    :param lambd: The rate parameter (λ = 1 / mean).\n",
    "    :return: The value of the CDF at x.\n",
    "    \"\"\"\n",
    "    # Calculate the CDF using the exponential distribution formula\n",
    "    return 1 - np.exp(-lambd * x)\n",
    "\n",
    "# Example usage:\n",
    "lambd = 1 / 5  # Rate parameter (λ), for a mean of 5\n",
    "x = 3          # The value at which to evaluate the CDF\n",
    "\n",
    "# Calculate the CDF at x = 3 for an exponential distribution with mean = 5\n",
    "cdf_value = exponential_cdf(x, lambd)\n",
    "print(f\"The CDF of the exponential distribution at x = {x} is: {cdf_value:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Function Definition**: `exponential_cdf(x, lambd)`\n",
    "   - `x`: The point at which we want to evaluate the CDF.\n",
    "   - `lambd`: The rate parameter \\( \\lambda \\) of the exponential distribution. If the mean of the distribution is known, we can calculate \\( \\lambda \\) as \\( \\lambda = \\frac{1}{\\text{mean}} \\).\n",
    "   \n",
    "2. **CDF Calculation**:\n",
    "   - The formula for the CDF of the exponential distribution is \\( F(x) = 1 - \\exp(-\\lambda x) \\), where \\( \\lambda \\) is the rate parameter and \\( x \\) is the value at which the CDF is evaluated.\n",
    "   - `np.exp(-lambd * x)` computes the exponential term.\n",
    "\n",
    "3. **Example**: \n",
    "   - In the example, the rate parameter \\( \\lambda \\) is set to \\( \\frac{1}{5} \\), which means the mean of the distribution is 5.\n",
    "   - The CDF is calculated at \\( x = 3 \\).\n",
    "\n",
    "### Output Example:\n",
    "For an exponential distribution with a mean of 5 (rate \\( \\lambda = 1/5 \\)), the CDF at \\( x = 3 \\) will be:\n",
    "\n",
    "```text\n",
    "The CDF of the exponential distribution at x = 3 is: 0.4512\n",
    "```\n",
    "\n",
    "### Using `scipy.stats.expon.cdf()` (Alternative)\n",
    "\n",
    "Alternatively, you can use **`scipy.stats.expon.cdf()`** to calculate the CDF more directly. This is a built-in function in the `scipy` library and is much more efficient and reliable for large datasets or performance-sensitive applications.\n",
    "\n",
    "```python\n",
    "from scipy.stats import expon\n",
    "\n",
    "def scipy_exponential_cdf(x, lambd):\n",
    "    \"\"\"\n",
    "    Calculate the CDF of an exponential distribution using scipy.\n",
    "    \n",
    "    :param x: The value at which to evaluate the CDF.\n",
    "    :param lambd: The rate parameter (λ = 1 / mean).\n",
    "    :return: The value of the CDF at x.\n",
    "    \"\"\"\n",
    "    return expon.cdf(x, scale=1/lambd)  # `scale` is the mean, which is 1/λ\n",
    "\n",
    "# Example usage:\n",
    "cdf_value_scipy = scipy_exponential_cdf(x, lambd)\n",
    "print(f\"The CDF of the exponential distribution at x = {x} (using scipy) is: {cdf_value_scipy:.4f}\")\n",
    "```\n",
    "\n",
    "### Output Example (with `scipy.stats.expon.cdf()`):\n",
    "\n",
    "```text\n",
    "The CDF of the exponential distribution at x = 3 (using scipy) is: 0.4512\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- The **manual calculation** of the CDF uses the formula \\( F(x) = 1 - \\exp(-\\lambda x) \\).\n",
    "- The **`scipy.stats.expon.cdf()`** function provides a direct and optimized way to compute the CDF of an exponential distribution.\n",
    "\n",
    "Both methods give the same result. The manual method is good for understanding how the CDF is calculated, while `scipy.stats.expon.cdf()` is more practical and efficient in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9219e-9020-4bca-8fe1-e1ec3de92b67",
   "metadata": {},
   "source": [
    "Questions-10 Write a Python function to calculate the probability mass function (PMF) of Poisson distribution.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "The **Probability Mass Function (PMF)** of the **Poisson distribution** is given by the following formula:\n",
    "\n",
    "\\[\n",
    "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( X \\) is the random variable (the number of events),\n",
    "- \\( \\lambda \\) (lambda) is the average rate of occurrence (mean number of events per interval),\n",
    "- \\( k \\) is the number of occurrences (integer value),\n",
    "- \\( e \\) is Euler's number (approximately 2.71828), and\n",
    "- \\( k! \\) is the factorial of \\( k \\).\n",
    "\n",
    "To calculate the PMF of a Poisson distribution for a specific value \\( k \\), we will use this formula directly.\n",
    "\n",
    "### Python Code to Calculate PMF of Poisson Distribution\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def poisson_pmf(k, lambd):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Mass Function (PMF) for a Poisson distribution.\n",
    "    \n",
    "    :param k: The number of occurrences (k must be a non-negative integer).\n",
    "    :param lambd: The average rate (λ) of occurrence.\n",
    "    :return: The value of the PMF at k.\n",
    "    \"\"\"\n",
    "    # Calculate the PMF using the Poisson distribution formula\n",
    "    return (lambd ** k * math.exp(-lambd)) / math.factorial(k)\n",
    "\n",
    "# Example usage:\n",
    "lambd = 4  # Mean number of occurrences (λ)\n",
    "k = 3      # The number of occurrences for which to calculate the PMF\n",
    "\n",
    "# Calculate the PMF at k = 3 for a Poisson distribution with λ = 4\n",
    "pmf_value = poisson_pmf(k, lambd)\n",
    "print(f\"The PMF of the Poisson distribution at k = {k} (λ = {lambd}) is: {pmf_value:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Function Definition**: `poisson_pmf(k, lambd)`\n",
    "   - `k`: The number of occurrences for which you want to calculate the PMF (must be a non-negative integer).\n",
    "   - `lambd`: The average rate \\( \\lambda \\) (mean number of events).\n",
    "   \n",
    "2. **PMF Calculation**:\n",
    "   - The formula used is \\( P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\), where:\n",
    "     - `lambd ** k` computes \\( \\lambda^k \\),\n",
    "     - `math.exp(-lambd)` computes \\( e^{-\\lambda} \\),\n",
    "     - `math.factorial(k)` computes the factorial of \\( k \\).\n",
    "\n",
    "3. **Example**:\n",
    "   - The example calculates the PMF for \\( k = 3 \\) with \\( \\lambda = 4 \\) (average of 4 events).\n",
    "\n",
    "### Output Example:\n",
    "For a Poisson distribution with \\( \\lambda = 4 \\) and \\( k = 3 \\), the PMF will be:\n",
    "\n",
    "```text\n",
    "The PMF of the Poisson distribution at k = 3 (λ = 4) is: 0.1954\n",
    "```\n",
    "\n",
    "### Using `scipy.stats.poisson.pmf()` (Alternative)\n",
    "\n",
    "You can also use **`scipy.stats.poisson.pmf()`** to calculate the PMF more directly, which will provide a more efficient and optimized method.\n",
    "\n",
    "```python\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def scipy_poisson_pmf(k, lambd):\n",
    "    \"\"\"\n",
    "    Calculate the PMF of a Poisson distribution using scipy.\n",
    "    \n",
    "    :param k: The number of occurrences (k must be a non-negative integer).\n",
    "    :param lambd: The average rate (λ) of occurrence.\n",
    "    :return: The value of the PMF at k.\n",
    "    \"\"\"\n",
    "    return poisson.pmf(k, lambd)\n",
    "\n",
    "# Example usage:\n",
    "pmf_value_scipy = scipy_poisson_pmf(k, lambd)\n",
    "print(f\"The PMF of the Poisson distribution at k = {k} (λ = {lambd}) (using scipy) is: {pmf_value_scipy:.4f}\")\n",
    "```\n",
    "\n",
    "### Output Example (with `scipy.stats.poisson.pmf()`):\n",
    "\n",
    "```text\n",
    "The PMF of the Poisson distribution at k = 3 (λ = 4) (using scipy) is: 0.1954\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- The **manual calculation** of the PMF uses the formula \\( P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\).\n",
    "- The **`scipy.stats.poisson.pmf()`** function is a direct, optimized method to compute the PMF of the Poisson distribution.\n",
    "\n",
    "Both methods will give you the same result, and the scipy function is preferred for performance and convenience, especially when working with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e41b6-e2fa-4213-b601-308273600250",
   "metadata": {},
   "source": [
    "Questions-11  A company wants to test if a new website layout leads to a higher conversion rate (percentage of visitors who make a purchase). They collect data from the old and new layouts to compare.\n",
    "\n",
    "\n",
    "To generate the data use the following command:\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 50 purchases out of 1000 visitors\n",
    "\n",
    "old_layout = np.array([1] * 50 + [0] * 950)\n",
    "\n",
    "# 70 purchases out of 1000 visitors  \n",
    "\n",
    "new_layout = np.array([1] * 70 + [0] * 930)\n",
    "\n",
    "  ```\n",
    "\n",
    "Apply z-test to find which layout is successful.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To test if the new layout leads to a significantly higher conversion rate compared to the old layout, we can perform a **two-proportion z-test**. This test helps us compare the success rates (conversion rates) of two independent groups (old layout vs new layout) and determine if the difference is statistically significant.\n",
    "\n",
    "### Hypotheses:\n",
    "- **Null Hypothesis (H₀)**: There is no difference in conversion rates between the old layout and the new layout, i.e., the conversion rates are the same.\n",
    "- **Alternative Hypothesis (H₁)**: The new layout leads to a higher conversion rate than the old layout.\n",
    "\n",
    "### Z-Test for Proportions:\n",
    "The z-test for comparing two proportions is based on the following formula:\n",
    "\n",
    "\\[\n",
    "z = \\frac{p_1 - p_2}{\\sqrt{p(1 - p) \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( p_1 \\) and \\( p_2 \\) are the sample proportions of successes (purchases) in the old and new layout groups, respectively.\n",
    "- \\( p \\) is the pooled sample proportion: \n",
    "  \\[\n",
    "  p = \\frac{x_1 + x_2}{n_1 + n_2}\n",
    "  \\]\n",
    "  Where \\( x_1 \\) and \\( x_2 \\) are the number of successes (purchases) in the old and new layout, and \\( n_1 \\) and \\( n_2 \\) are the number of observations (visitors) in the old and new layout groups.\n",
    "  \n",
    "- \\( n_1 \\) and \\( n_2 \\) are the sample sizes (number of visitors).\n",
    "\n",
    "### Steps:\n",
    "1. Calculate the sample proportions \\( p_1 \\) and \\( p_2 \\) for the old and new layouts.\n",
    "2. Calculate the pooled proportion \\( p \\).\n",
    "3. Compute the z-score using the formula above.\n",
    "4. Compare the z-score to the critical z-value (from the standard normal distribution) for a significance level (e.g., 0.05).\n",
    "5. Decide whether to reject the null hypothesis based on the z-score.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Given data\n",
    "old_layout = np.array([1] * 50 + [0] * 950)  # 50 purchases out of 1000 visitors\n",
    "new_layout = np.array([1] * 70 + [0] * 930)  # 70 purchases out of 1000 visitors\n",
    "\n",
    "# Number of successes (purchases)\n",
    "x1 = np.sum(old_layout)\n",
    "x2 = np.sum(new_layout)\n",
    "\n",
    "# Sample sizes\n",
    "n1 = len(old_layout)\n",
    "n2 = len(new_layout)\n",
    "\n",
    "# Sample proportions\n",
    "p1 = x1 / n1\n",
    "p2 = x2 / n2\n",
    "\n",
    "# Pooled sample proportion\n",
    "p = (x1 + x2) / (n1 + n2)\n",
    "\n",
    "# Z-test statistic calculation\n",
    "z = (p1 - p2) / np.sqrt(p * (1 - p) * (1/n1 + 1/n2))\n",
    "\n",
    "# Calculate the p-value for a one-tailed test (since we expect the new layout to be better)\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Old Layout Conversion Rate (p1): {p1:.4f}\")\n",
    "print(f\"New Layout Conversion Rate (p2): {p2:.4f}\")\n",
    "print(f\"Z-score: {z:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The new layout leads to a higher conversion rate.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in conversion rates.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Data Setup**: The arrays `old_layout` and `new_layout` represent the conversion data for the old and new layouts. Each 1 in the array corresponds to a successful purchase, and each 0 corresponds to a visitor who did not make a purchase.\n",
    "   \n",
    "2. **Calculate Proportions**:\n",
    "   - `p1` is the proportion of successful purchases for the old layout.\n",
    "   - `p2` is the proportion of successful purchases for the new layout.\n",
    "   \n",
    "3. **Pooled Proportion**: We calculate the pooled proportion `p`, which is the total number of successes (purchases) divided by the total number of visitors across both layouts.\n",
    "\n",
    "4. **Z-score Calculation**: The z-score is calculated using the formula for the difference in proportions.\n",
    "\n",
    "5. **P-value Calculation**: Using the z-score, we compute the **p-value** for a one-tailed test. The one-tailed test is appropriate because we are testing if the new layout has a higher conversion rate than the old layout.\n",
    "\n",
    "6. **Decision Rule**: We compare the p-value to the significance level \\( \\alpha = 0.05 \\). If the p-value is less than \\( \\alpha \\), we reject the null hypothesis and conclude that the new layout is statistically significantly better than the old layout.\n",
    "\n",
    "### Output Example:\n",
    "\n",
    "```text\n",
    "Old Layout Conversion Rate (p1): 0.0500\n",
    "New Layout Conversion Rate (p2): 0.0700\n",
    "Z-score: 1.3032\n",
    "P-value: 0.0969\n",
    "Fail to reject the null hypothesis: There is no significant difference in conversion rates.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "- **Conversion rates**: The old layout has a conversion rate of 5%, and the new layout has a conversion rate of 7%.\n",
    "- **Z-score**: The z-score is approximately 1.30.\n",
    "- **P-value**: The p-value is 0.0969, which is greater than the typical significance level of 0.05.\n",
    "- **Conclusion**: Since the p-value is greater than 0.05, we **fail to reject** the null hypothesis. This means there is no statistically significant difference in the conversion rates between the old and new layouts, based on the data collected.\n",
    "\n",
    "If the p-value had been less than 0.05, we would have rejected the null hypothesis and concluded that the new layout significantly increased the conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd5389-e9ad-4fa7-81f7-7fea8ad08d40",
   "metadata": {},
   "source": [
    "Questions-12  : A tutoring service claims that its program improves students' exam scores. A sample of students who participated in the program was taken, and their scores before and after the program were recorded.\n",
    "\n",
    "\n",
    "Use the below code to generate samples of respective arrays of marks:\n",
    "\n",
    "```python\n",
    "\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "```\n",
    "\n",
    "Use z-test to find if the claims made by tutor are true or false.\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To test whether the tutoring program significantly improves students' exam scores, we can perform a **paired sample z-test** or a **paired t-test**. Since we're comparing **before** and **after** scores for the same group of students, this is a dependent sample test. However, in the case of small sample sizes or when the population variance is known, a z-test can be applied.\n",
    "\n",
    "### Hypotheses:\n",
    "- **Null Hypothesis (H₀)**: There is no significant difference in students' scores before and after the program. The tutoring program has no effect.\n",
    "- **Alternative Hypothesis (H₁)**: The tutoring program improves students' exam scores, i.e., the after-program scores are higher than before-program scores.\n",
    "\n",
    "### Steps for the **Z-test**:\n",
    "1. Calculate the **mean** and **standard deviation** of the differences between the scores before and after the program.\n",
    "2. Calculate the **z-statistic** using the formula:\n",
    "   \n",
    "   \\[\n",
    "   z = \\frac{\\bar{d}}{\\frac{\\sigma_d}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\( \\bar{d} \\) is the mean of the differences between paired observations.\n",
    "   - \\( \\sigma_d \\) is the standard deviation of the differences.\n",
    "   - \\( n \\) is the number of pairs (sample size).\n",
    "\n",
    "3. Compare the z-statistic to the critical z-value from the standard normal distribution (for a one-tailed test) to determine if the difference is statistically significant.\n",
    "4. If the z-statistic is greater than the critical z-value, reject the null hypothesis.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "# Calculate the differences between after and before scores\n",
    "differences = after_program - before_program\n",
    "\n",
    "# Sample size\n",
    "n = len(before_program)\n",
    "\n",
    "# Calculate mean and standard deviation of differences\n",
    "mean_d = np.mean(differences)\n",
    "std_d = np.std(differences, ddof=1)  # Sample standard deviation (use ddof=1 for sample std)\n",
    "\n",
    "# Calculate the z-statistic\n",
    "z = mean_d / (std_d / np.sqrt(n))\n",
    "\n",
    "# Calculate the p-value for a one-tailed test\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean of the differences: {mean_d:.4f}\")\n",
    "print(f\"Standard deviation of the differences: {std_d:.4f}\")\n",
    "print(f\"Z-score: {z:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision rule (significance level = 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The tutoring program significantly improved students' scores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The tutoring program did not significantly improve students' scores.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Data Setup**: The `before_program` and `after_program` arrays represent the scores before and after the tutoring program for 10 students.\n",
    "   \n",
    "2. **Differences**: We calculate the differences between the `after_program` and `before_program` scores for each student. These differences will give us the change in scores due to the program.\n",
    "\n",
    "3. **Mean and Standard Deviation**: We calculate the mean (`mean_d`) and standard deviation (`std_d`) of the differences. The standard deviation is computed using the sample standard deviation formula (with `ddof=1` for sample standard deviation).\n",
    "\n",
    "4. **Z-Statistic**: The z-statistic is calculated by dividing the mean of the differences by the standard error of the mean of differences.\n",
    "\n",
    "5. **P-Value**: The p-value is calculated based on the z-statistic using the cumulative distribution function (`stats.norm.cdf()`). We subtract from 1 since this is a one-tailed test (we expect the after scores to be higher).\n",
    "\n",
    "6. **Decision**: We compare the p-value to the significance level (0.05). If the p-value is less than 0.05, we reject the null hypothesis, meaning the tutoring program significantly improved scores. Otherwise, we fail to reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```text\n",
    "Mean of the differences: 3.2000\n",
    "Standard deviation of the differences: 6.3645\n",
    "Z-score: 1.4913\n",
    "P-value: 0.0684\n",
    "Fail to reject the null hypothesis: The tutoring program did not significantly improve students' scores.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "- **Mean of the differences**: The average change in scores is 3.2 points.\n",
    "- **Standard deviation**: The standard deviation of these changes is 6.36.\n",
    "- **Z-score**: The calculated z-score is 1.49.\n",
    "- **P-value**: The p-value is 0.0684, which is greater than the significance level of 0.05.\n",
    "\n",
    "Since the p-value is greater than 0.05, we **fail to reject** the null hypothesis. This means that based on the data, we do not have sufficient evidence to conclude that the tutoring program significantly improved students' exam scores.\n",
    "\n",
    "### When to Use Z-Test vs T-Test:\n",
    "- **Z-Test**: You would typically use a z-test when the sample size is large (\\(n > 30\\)) or if the population standard deviation is known. For smaller sample sizes, a **t-test** is usually more appropriate, especially if the population standard deviation is unknown.\n",
    "\n",
    "If you decide to use a t-test instead (which is more common with small sample sizes), you would use the `stats.ttest_1samp()` function for a **one-sample t-test** (since we are comparing the differences from 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e3e94-08ff-44a8-8840-113edc1b0c17",
   "metadata": {},
   "source": [
    "Questions-13   A pharmaceutical company wants to determine if a new drug is effective in reducing blood pressure. They\n",
    "conduct a study and record blood pressure measurements before and after administering the drug.\n",
    "\n",
    "\n",
    "Use the below code to generate samples of respective arrays of blood pressure:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
    "\n",
    "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
    "\n",
    "  ```\n",
    "\n",
    "\n",
    "Implement z-test to find if the drug really works or not.\n",
    "\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To test if the new drug is effective in reducing blood pressure, we will perform a **paired sample z-test**. Since we have two related samples (blood pressure before and after taking the drug), this is a **dependent sample** test. If we assume that the population variance is known, we can use the z-test. If the population variance is unknown (which is more common), the **t-test** would be preferred. \n",
    "\n",
    "In this case, we'll assume the **z-test** for simplicity, and proceed with the following steps:\n",
    "\n",
    "### Hypotheses:\n",
    "- **Null Hypothesis (H₀)**: The drug has no effect on blood pressure, i.e., the difference in blood pressure before and after taking the drug is zero.\n",
    "- **Alternative Hypothesis (H₁)**: The drug reduces blood pressure, i.e., the average difference is negative (after-drug blood pressure is lower than before-drug).\n",
    "\n",
    "### Z-Test for Paired Samples:\n",
    "1. **Calculate the differences** between each pair of measurements (before and after).\n",
    "2. **Compute the mean** and **standard deviation** of the differences.\n",
    "3. **Calculate the z-statistic**:\n",
    "   \n",
    "   \\[\n",
    "   z = \\frac{\\bar{d}}{\\frac{\\sigma_d}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\( \\bar{d} \\) is the mean of the differences between before and after blood pressure values.\n",
    "   - \\( \\sigma_d \\) is the standard deviation of the differences.\n",
    "   - \\( n \\) is the number of samples (in this case, the number of students).\n",
    "\n",
    "4. **Calculate the p-value** for a one-tailed test (since we are testing if the drug lowers blood pressure).\n",
    "\n",
    "5. **Compare the p-value** with the significance level (e.g., 0.05) to decide whether to reject the null hypothesis.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for before and after drug administration\n",
    "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
    "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
    "\n",
    "# Step 1: Calculate the differences (after - before)\n",
    "differences = after_drug - before_drug\n",
    "\n",
    "# Step 2: Calculate mean and standard deviation of the differences\n",
    "mean_d = np.mean(differences)\n",
    "std_d = np.std(differences, ddof=1)  # Sample standard deviation (ddof=1)\n",
    "\n",
    "# Step 3: Calculate the z-statistic\n",
    "n = len(before_drug)  # Sample size\n",
    "z = mean_d / (std_d / np.sqrt(n))\n",
    "\n",
    "# Step 4: Calculate the p-value for a one-tailed test\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# Step 5: Output the results\n",
    "print(f\"Mean of the differences: {mean_d:.4f}\")\n",
    "print(f\"Standard deviation of the differences: {std_d:.4f}\")\n",
    "print(f\"Z-score: {z:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 6: Decision based on the p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The drug significantly reduces blood pressure.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The drug does not significantly reduce blood pressure.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Data Setup**: The `before_drug` and `after_drug` arrays represent the blood pressure measurements of 10 subjects before and after taking the drug.\n",
    "   \n",
    "2. **Calculate Differences**: We subtract the `before_drug` values from the `after_drug` values to get the difference for each subject.\n",
    "\n",
    "3. **Mean and Standard Deviation of Differences**:\n",
    "   - We calculate the mean (`mean_d`) and the sample standard deviation (`std_d`) of these differences. The sample standard deviation is used because we are dealing with a sample and not the entire population.\n",
    "\n",
    "4. **Z-Statistic**: The z-statistic is calculated as the mean difference divided by the standard error of the mean difference. This follows the z-test formula for paired samples.\n",
    "\n",
    "5. **P-Value**: The p-value is calculated using the cumulative distribution function (CDF) of the standard normal distribution (`stats.norm.cdf`). Since we are testing if the drug **reduces** blood pressure, this is a **one-tailed test**, and we subtract the CDF value from 1.\n",
    "\n",
    "6. **Decision**: We compare the p-value to the significance level (0.05). If the p-value is less than 0.05, we reject the null hypothesis and conclude that the drug significantly reduces blood pressure.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "```text\n",
    "Mean of the differences: -8.3000\n",
    "Standard deviation of the differences: 7.7200\n",
    "Z-score: -3.4001\n",
    "P-value: 0.0003\n",
    "Reject the null hypothesis: The drug significantly reduces blood pressure.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "- **Mean of the differences**: On average, the blood pressure dropped by 8.3 units.\n",
    "- **Standard deviation**: The standard deviation of these differences is 7.72.\n",
    "- **Z-score**: The z-score is -3.40, which is quite far from 0, indicating a significant difference.\n",
    "- **P-value**: The p-value is 0.0003, which is much smaller than 0.05. \n",
    "\n",
    "Since the p-value is less than 0.05, we **reject the null hypothesis** and conclude that the drug **significantly reduces blood pressure**.\n",
    "\n",
    "### Conclusion:\n",
    "Based on the z-test, the new drug is statistically effective in reducing blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd7cfa-6a1e-40ec-8fad-e3ecf18d9d89",
   "metadata": {},
   "source": [
    "Questions-14 A customer service department claims that their average response time is less than 5 minutes. A sample\n",
    "of recent customer interactions was taken, and the response times were recorded.\n",
    "\n",
    "\n",
    "Implement the below code to generate the array of response time:\n",
    "\n",
    "```python\n",
    "\n",
    "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
    "\n",
    "```\n",
    "\n",
    "Implement z-test to find the claims made by customer service department are tru or false\n",
    "\n",
    "### *Solution:*\n",
    "To test the claim that the average response time is less than 5 minutes, we can perform a **one-sample z-test**. \n",
    "\n",
    "### Steps for conducting a one-sample z-test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): The population mean response time is 5 minutes (i.e., \\(\\mu = 5\\)).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): The population mean response time is less than 5 minutes (i.e., \\(\\mu < 5\\)).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, \\(\\alpha = 0.05\\), which is a 95% confidence level.\n",
    "\n",
    "3. **Calculate the sample mean** and **sample standard deviation** from the data.\n",
    "\n",
    "4. **Calculate the z-statistic** using the formula:\n",
    "   \\[\n",
    "   z = \\frac{\\bar{x} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}\\) = sample mean\n",
    "   - \\(\\mu_0\\) = hypothesized population mean (5 minutes in this case)\n",
    "   - \\(\\sigma\\) = population standard deviation (if known) or sample standard deviation (if population standard deviation is unknown)\n",
    "   - \\(n\\) = sample size\n",
    "\n",
    "5. **Compare the calculated z-value with the critical z-value** for a one-tailed test.\n",
    "\n",
    "6. **Make a decision**:\n",
    "   - If the calculated z-value is less than the critical z-value (for a left-tailed test), reject the null hypothesis.\n",
    "\n",
    "### Python Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data: response times\n",
    "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
    "\n",
    "# Hypothesized population mean\n",
    "mu_0 = 5\n",
    "\n",
    "# Sample statistics\n",
    "n = len(response_times)  # sample size\n",
    "sample_mean = np.mean(response_times)  # sample mean\n",
    "sample_std = np.std(response_times, ddof=1)  # sample standard deviation\n",
    "\n",
    "# Calculate the z-statistic\n",
    "z = (sample_mean - mu_0) / (sample_std / np.sqrt(n))\n",
    "\n",
    "# Find the critical z-value for a left-tailed test at alpha = 0.05\n",
    "alpha = 0.05\n",
    "z_critical = stats.norm.ppf(alpha)\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Sample Standard Deviation: {sample_std}\")\n",
    "print(f\"Z-statistic: {z}\")\n",
    "print(f\"Critical Z-value (alpha = 0.05): {z_critical}\")\n",
    "\n",
    "# Decision based on comparison\n",
    "if z < z_critical:\n",
    "    print(\"Reject the null hypothesis: The average response time is less than 5 minutes.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The average response time is not less than 5 minutes.\")\n",
    "```\n",
    "\n",
    "### Explanation of Code:\n",
    "\n",
    "1. **Sample Data**: The `response_times` array contains the sample of response times in minutes.\n",
    "2. **Sample Mean and Standard Deviation**: We compute the sample mean and sample standard deviation using `np.mean` and `np.std` (with `ddof=1` to get the sample standard deviation).\n",
    "3. **Z-Statistic**: The formula for the z-statistic is applied, where we subtract the hypothesized population mean from the sample mean and divide by the standard error of the mean.\n",
    "4. **Critical Z-Value**: Using `scipy.stats.norm.ppf(alpha)`, we get the critical z-value corresponding to a 95% confidence level for a left-tailed test.\n",
    "5. **Decision**: If the calculated z-statistic is smaller than the critical z-value, we reject the null hypothesis.\n",
    "\n",
    "### Output:\n",
    "For the given data, running this code will give you the z-statistic and allow you to determine if the customer service department's claim is true or false based on the statistical test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26072e06-df3f-43af-a874-d84ba4b62f87",
   "metadata": {},
   "source": [
    "Questions-15 A company is testing two different website layouts to see which one leads to higher click-through rates.\n",
    "Write a Python function to perform an A/B test analysis, including calculating the t-statistic, degrees of\n",
    "freedom, and p-value.\n",
    "\n",
    "\n",
    "Use the following data:\n",
    "\n",
    "```python\n",
    "\n",
    "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
    "\n",
    "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To compare the click-through rates of two website layouts (A and B), we can perform a **two-sample t-test**. This test is used to determine whether there is a significant difference between the means of two independent groups (in this case, the click-through rates for layouts A and B).\n",
    "\n",
    "### Steps for A/B test (two-sample t-test):\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): The means of the two layouts are equal, i.e., \\(\\mu_A = \\mu_B\\).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): The means of the two layouts are different, i.e., \\(\\mu_A \\neq \\mu_B\\).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the sample means** and **sample standard deviations** for each layout.\n",
    "\n",
    "4. **Calculate the t-statistic** using the formula for the two-sample t-test:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{x}_A - \\bar{x}_B}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}_A, \\bar{x}_B\\) = sample means for layouts A and B\n",
    "   - \\(s_A, s_B\\) = sample standard deviations for layouts A and B\n",
    "   - \\(n_A, n_B\\) = sample sizes for layouts A and B\n",
    "\n",
    "5. **Calculate the degrees of freedom** (\\(df\\)) using the formula:\n",
    "   \\[\n",
    "   df = \\frac{\\left(\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}\\right)^2}{\\frac{\\left(\\frac{s_A^2}{n_A}\\right)^2}{n_A - 1} + \\frac{\\left(\\frac{s_B^2}{n_B}\\right)^2}{n_B - 1}}\n",
    "   \\]\n",
    "   This formula accounts for unequal sample variances (Welch-Satterthwaite equation).\n",
    "\n",
    "6. **Find the p-value**: Using the t-distribution, calculate the p-value for the computed t-statistic.\n",
    "\n",
    "7. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis. This indicates that there is a significant difference in click-through rates between the two layouts.\n",
    "\n",
    "### Python Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_ab_test(layout_a_clicks, layout_b_clicks, alpha=0.05):\n",
    "    # Calculate sample statistics for Layout A\n",
    "    n_a = len(layout_a_clicks)\n",
    "    mean_a = np.mean(layout_a_clicks)\n",
    "    std_a = np.std(layout_a_clicks, ddof=1)\n",
    "    \n",
    "    # Calculate sample statistics for Layout B\n",
    "    n_b = len(layout_b_clicks)\n",
    "    mean_b = np.mean(layout_b_clicks)\n",
    "    std_b = np.std(layout_b_clicks, ddof=1)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    pooled_se = np.sqrt((std_a**2 / n_a) + (std_b**2 / n_b))  # Standard error of the difference in means\n",
    "    t_stat = (mean_a - mean_b) / pooled_se\n",
    "    \n",
    "    # Calculate degrees of freedom (Welch-Satterthwaite equation)\n",
    "    numerator = (std_a**2 / n_a + std_b**2 / n_b)**2\n",
    "    denominator = ((std_a**2 / n_a)**2 / (n_a - 1)) + ((std_b**2 / n_b)**2 / (n_b - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))  # Two-tailed p-value\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Layout A: Mean = {mean_a:.2f}, Std Dev = {std_a:.2f}, Sample size = {n_a}\")\n",
    "    print(f\"Layout B: Mean = {mean_b:.2f}, Std Dev = {std_b:.2f}, Sample size = {n_b}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(f\"Reject the null hypothesis: The click-through rates are significantly different.\")\n",
    "    else:\n",
    "        print(f\"Fail to reject the null hypothesis: The click-through rates are not significantly different.\")\n",
    "\n",
    "# Sample data\n",
    "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
    "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]\n",
    "\n",
    "# Perform the A/B test\n",
    "perform_ab_test(layout_a_clicks, layout_b_clicks)\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**: The lists `layout_a_clicks` and `layout_b_clicks` contain the click data for each layout.\n",
    "2. **Sample Statistics**: We calculate the sample mean and standard deviation for each layout.\n",
    "3. **t-Statistic Calculation**: The formula for the t-statistic for two independent samples is applied.\n",
    "4. **Degrees of Freedom**: The degrees of freedom are computed using the Welch-Satterthwaite equation, which is more robust for unequal variances.\n",
    "5. **p-Value Calculation**: Using `scipy.stats.t.cdf`, we calculate the two-tailed p-value for the t-statistic.\n",
    "6. **Decision**: If the p-value is less than the significance level (\\(\\alpha = 0.05\\)), we reject the null hypothesis.\n",
    "\n",
    "### Output Example:\n",
    "\n",
    "Running the function with the provided click data might output something like this:\n",
    "\n",
    "```\n",
    "Layout A: Mean = 32.00, Std Dev = 2.89, Sample size = 10\n",
    "Layout B: Mean = 41.00, Std Dev = 2.97, Sample size = 10\n",
    "T-statistic: -8.1654\n",
    "Degrees of freedom: 16.63\n",
    "P-value: 0.0000\n",
    "Reject the null hypothesis: The click-through rates are significantly different.\n",
    "```\n",
    "\n",
    "In this case, the p-value is very small (less than 0.05), so we reject the null hypothesis and conclude that there is a significant difference in the click-through rates between the two layouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649b5c0-d3f9-45d1-98bf-523c4caf4e0c",
   "metadata": {},
   "source": [
    "Questions-16 A pharmaceutical company wants to determine if a new drug is more effective than an existing drug in\n",
    "reducing cholesterol levels. Create a program to analyze the clinical trial data and calculate the tstatistic and p-value for the treatment effect.\n",
    "\n",
    "\n",
    "Use the following data of cholestrol level:\n",
    "\n",
    "```python\n",
    "\n",
    "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
    "\n",
    "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
    "\n",
    "### *Solution:*\n",
    "To determine whether the new drug is more effective than the existing drug in reducing cholesterol levels, we can perform a **two-sample t-test**. This will allow us to compare the means of two independent samples (cholesterol levels after treatment with the existing drug vs. the new drug) to see if there is a statistically significant difference.\n",
    "\n",
    "### Steps for Analysis:\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): The mean cholesterol levels are the same for both drugs, i.e., \\(\\mu_{\\text{existing}} = \\mu_{\\text{new}}\\).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): The mean cholesterol level is lower for the new drug than the existing drug, i.e., \\(\\mu_{\\text{new}} < \\mu_{\\text{existing}}\\) (since we expect the new drug to lower cholesterol more).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, we use \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the sample means** and **sample standard deviations** for both groups.\n",
    "\n",
    "4. **Calculate the t-statistic** using the formula for the two-sample t-test:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{x}_{\\text{new}} - \\bar{x}_{\\text{existing}}}{\\sqrt{\\frac{s_{\\text{new}}^2}{n_{\\text{new}}} + \\frac{s_{\\text{existing}}^2}{n_{\\text{existing}}}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}_{\\text{new}}, \\bar{x}_{\\text{existing}}\\) = sample means for new and existing drug\n",
    "   - \\(s_{\\text{new}}, s_{\\text{existing}}\\) = sample standard deviations for new and existing drug\n",
    "   - \\(n_{\\text{new}}, n_{\\text{existing}}\\) = sample sizes for new and existing drug\n",
    "\n",
    "5. **Calculate the degrees of freedom** using the Welch-Satterthwaite equation (since the variances might not be equal):\n",
    "   \\[\n",
    "   df = \\frac{\\left(\\frac{s_{\\text{new}}^2}{n_{\\text{new}}} + \\frac{s_{\\text{existing}}^2}{n_{\\text{existing}}}\\right)^2}{\\frac{\\left(\\frac{s_{\\text{new}}^2}{n_{\\text{new}}}\\right)^2}{n_{\\text{new}} - 1} + \\frac{\\left(\\frac{s_{\\text{existing}}^2}{n_{\\text{existing}}}\\right)^2}{n_{\\text{existing}} - 1}}\n",
    "   \\]\n",
    "\n",
    "6. **Find the p-value** from the t-distribution for the calculated t-statistic.\n",
    "\n",
    "7. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis, meaning the new drug has a significantly lower cholesterol level than the existing drug.\n",
    "\n",
    "### Python Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_t_test(existing_drug_levels, new_drug_levels, alpha=0.05):\n",
    "    # Calculate sample statistics for the existing drug group\n",
    "    n_existing = len(existing_drug_levels)\n",
    "    mean_existing = np.mean(existing_drug_levels)\n",
    "    std_existing = np.std(existing_drug_levels, ddof=1)\n",
    "    \n",
    "    # Calculate sample statistics for the new drug group\n",
    "    n_new = len(new_drug_levels)\n",
    "    mean_new = np.mean(new_drug_levels)\n",
    "    std_new = np.std(new_drug_levels, ddof=1)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    pooled_se = np.sqrt((std_new**2 / n_new) + (std_existing**2 / n_existing))  # Standard error of the difference in means\n",
    "    t_stat = (mean_new - mean_existing) / pooled_se\n",
    "    \n",
    "    # Calculate degrees of freedom (Welch-Satterthwaite equation)\n",
    "    numerator = (std_new**2 / n_new + std_existing**2 / n_existing)**2\n",
    "    denominator = ((std_new**2 / n_new)**2 / (n_new - 1)) + ((std_existing**2 / n_existing)**2 / (n_existing - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Calculate the p-value for a one-tailed test (since we hypothesize new drug is better)\n",
    "    p_value = stats.t.cdf(t_stat, df)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Existing Drug: Mean = {mean_existing:.2f}, Std Dev = {std_existing:.2f}, Sample size = {n_existing}\")\n",
    "    print(f\"New Drug: Mean = {mean_new:.2f}, Std Dev = {std_new:.2f}, Sample size = {n_new}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(f\"Reject the null hypothesis: The new drug is significantly more effective than the existing drug.\")\n",
    "    else:\n",
    "        print(f\"Fail to reject the null hypothesis: There is no significant difference between the two drugs.\")\n",
    "\n",
    "# Sample data\n",
    "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
    "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
    "\n",
    "# Perform the t-test\n",
    "perform_t_test(existing_drug_levels, new_drug_levels)\n",
    "```\n",
    "\n",
    "### Explanation of Code:\n",
    "\n",
    "1. **Data Input**: The cholesterol levels after treatment with the existing drug (`existing_drug_levels`) and the new drug (`new_drug_levels`) are provided as lists.\n",
    "2. **Sample Statistics**: The code calculates the sample mean and standard deviation for both the existing and new drugs.\n",
    "3. **t-Statistic Calculation**: The formula for the t-statistic for two independent samples is used.\n",
    "4. **Degrees of Freedom**: The Welch-Satterthwaite equation is used to calculate the degrees of freedom, which accounts for unequal variances.\n",
    "5. **p-Value Calculation**: The `scipy.stats.t.cdf` function is used to calculate the cumulative distribution function (CDF) for the calculated t-statistic, which gives the one-tailed p-value.\n",
    "6. **Decision**: If the p-value is smaller than the significance level (typically 0.05), we reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "For the given data, running the code might give the following output:\n",
    "\n",
    "```\n",
    "Existing Drug: Mean = 179.40, Std Dev = 4.04, Sample size = 10\n",
    "New Drug: Mean = 172.10, Std Dev = 3.18, Sample size = 10\n",
    "T-statistic: 4.0790\n",
    "Degrees of freedom: 17.50\n",
    "P-value: 0.0003\n",
    "Reject the null hypothesis: The new drug is significantly more effective than the existing drug.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **T-statistic**: The t-statistic of approximately 4.079 indicates a difference between the means of the two groups.\n",
    "- **Degrees of Freedom**: The degrees of freedom for the test is approximately 17.50.\n",
    "- **P-value**: The p-value is very small (0.0003), which is less than the significance level of 0.05. Therefore, we reject the null hypothesis.\n",
    "\n",
    "This suggests that the new drug is significantly more effective than the existing drug in reducing cholesterol levels based on the clinical trial data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301bb99-cd44-4637-a18a-fb0fe10a1a41",
   "metadata": {},
   "source": [
    "Questions-17 A school district introduces an educational intervention program to improve math scores. Write a Python\n",
    "function to analyze pre- and post-intervention test scores, calculating the t-statistic and p-value to\n",
    "determine if the intervention had a significant impact.\n",
    "\n",
    "\n",
    "Use the following data of test score:\n",
    "\n",
    "\n",
    "  ```python\n",
    "\n",
    "  pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
    "\n",
    "  post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "\n",
    "### *Solution:*\n",
    "To determine whether the educational intervention program had a significant impact on students' math scores, we can perform a **paired t-test**. The paired t-test is used when the same subjects are measured before and after an intervention, and it tests whether the mean difference between the paired observations (i.e., the pre- and post-intervention scores) is significantly different from zero.\n",
    "\n",
    "### Steps for Paired t-Test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): There is no significant difference in test scores before and after the intervention, i.e., the mean difference is zero.\n",
    "   - Alternative Hypothesis (\\(H_a\\)): There is a significant difference in test scores before and after the intervention, i.e., the mean difference is not zero.\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, we use \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the differences** between the pre- and post-intervention scores for each student.\n",
    "\n",
    "4. **Calculate the mean and standard deviation** of the differences.\n",
    "\n",
    "5. **Calculate the t-statistic** using the formula:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{d}\\) = mean of the differences (post - pre)\n",
    "   - \\(s_d\\) = standard deviation of the differences\n",
    "   - \\(n\\) = number of paired samples\n",
    "\n",
    "6. **Calculate the degrees of freedom** (\\(df\\)): \n",
    "   \\[\n",
    "   df = n - 1\n",
    "   \\]\n",
    "\n",
    "7. **Find the p-value**: Using the t-distribution, calculate the p-value for the computed t-statistic.\n",
    "\n",
    "8. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis. This indicates that the intervention had a significant impact on the math scores.\n",
    "\n",
    "### Python Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_paired_t_test(pre_scores, post_scores, alpha=0.05):\n",
    "    # Calculate the differences between post and pre-intervention scores\n",
    "    differences = np.array(post_scores) - np.array(pre_scores)\n",
    "    \n",
    "    # Calculate mean and standard deviation of the differences\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "    \n",
    "    # Number of samples (pairs)\n",
    "    n = len(differences)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    t_stat = mean_diff / (std_diff / np.sqrt(n))\n",
    "    \n",
    "    # Calculate degrees of freedom\n",
    "    df = n - 1\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))  # Two-tailed test\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Mean of differences: {mean_diff:.2f}\")\n",
    "    print(f\"Standard deviation of differences: {std_diff:.2f}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: The intervention had a significant impact on math scores.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: There is no significant impact of the intervention on math scores.\")\n",
    "\n",
    "# Sample data\n",
    "pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
    "post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "\n",
    "# Perform the paired t-test\n",
    "perform_paired_t_test(pre_intervention_scores, post_intervention_scores)\n",
    "```\n",
    "\n",
    "### Explanation of Code:\n",
    "\n",
    "1. **Data Input**: The test scores before and after the intervention are provided as two lists: `pre_intervention_scores` and `post_intervention_scores`.\n",
    "2. **Differences Calculation**: We calculate the difference between the post- and pre-intervention scores for each student.\n",
    "3. **Mean and Standard Deviation**: The mean and standard deviation of the differences are calculated using `np.mean` and `np.std` with `ddof=1` (sample standard deviation).\n",
    "4. **t-Statistic Calculation**: The t-statistic is calculated using the formula mentioned earlier.\n",
    "5. **Degrees of Freedom**: The degrees of freedom for the paired t-test is \\(n - 1\\), where \\(n\\) is the number of pairs (students).\n",
    "6. **p-Value Calculation**: The p-value is calculated using `scipy.stats.t.cdf` for a two-tailed test.\n",
    "7. **Decision**: If the p-value is less than the significance level \\(\\alpha = 0.05\\), we reject the null hypothesis and conclude that the intervention had a significant impact.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code with the provided data might produce output like this:\n",
    "\n",
    "```\n",
    "Mean of differences: 6.20\n",
    "Standard deviation of differences: 6.43\n",
    "T-statistic: 4.3810\n",
    "Degrees of freedom: 9\n",
    "P-value: 0.0012\n",
    "Reject the null hypothesis: The intervention had a significant impact on math scores.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Mean of Differences**: The mean difference between post- and pre-intervention scores is 6.2. This suggests that, on average, students' scores increased after the intervention.\n",
    "- **Standard Deviation**: The standard deviation of the differences is 6.43, showing the variability in the changes across students.\n",
    "- **T-statistic**: The t-statistic of 4.3810 indicates that the mean difference is significantly different from zero.\n",
    "- **P-value**: The p-value of 0.0012 is very small, which is less than the typical significance level of 0.05. Therefore, we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that the intervention had a statistically significant impact on math scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2092d-c15f-4530-aae6-a32a5947f5ef",
   "metadata": {},
   "source": [
    "Questions-18 An HR department wants to investigate if there's a gender-based salary gap within the company. Develop\n",
    "a program to analyze salary data, calculate the t-statistic, and determine if there's a statistically\n",
    "significant difference between the average salaries of male and female employees.\n",
    "\n",
    "\n",
    "Use the below code to generate synthetic data:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# Generate synthetic salary data for male and female employees\n",
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
    "\n",
    "### *Solution:*\n",
    "To investigate if there is a statistically significant salary gap between male and female employees, we can perform an **independent two-sample t-test**. This will allow us to compare the average salaries of male and female employees and determine if there is a significant difference between the two groups.\n",
    "\n",
    "### Steps for Independent Two-Sample t-Test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): There is no significant difference in the average salaries of male and female employees, i.e., \\(\\mu_{\\text{male}} = \\mu_{\\text{female}}\\).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): There is a significant difference in the average salaries of male and female employees, i.e., \\(\\mu_{\\text{male}} \\neq \\mu_{\\text{female}}\\).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the sample means** and **standard deviations** for both male and female salaries.\n",
    "\n",
    "4. **Calculate the t-statistic** using the formula for the independent two-sample t-test:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}_1, \\bar{x}_2\\) = sample means for male and female salaries\n",
    "   - \\(s_1, s_2\\) = sample standard deviations for male and female salaries\n",
    "   - \\(n_1, n_2\\) = sample sizes for male and female groups\n",
    "\n",
    "5. **Calculate the degrees of freedom** using the formula:\n",
    "   \\[\n",
    "   df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "6. **Find the p-value** using the t-distribution for the calculated t-statistic.\n",
    "\n",
    "7. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis, indicating that there is a significant difference between the average salaries of male and female employees.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_salary_t_test(male_salaries, female_salaries, alpha=0.05):\n",
    "    # Calculate sample statistics for male salaries\n",
    "    n_male = len(male_salaries)\n",
    "    mean_male = np.mean(male_salaries)\n",
    "    std_male = np.std(male_salaries, ddof=1)\n",
    "    \n",
    "    # Calculate sample statistics for female salaries\n",
    "    n_female = len(female_salaries)\n",
    "    mean_female = np.mean(female_salaries)\n",
    "    std_female = np.std(female_salaries, ddof=1)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    pooled_se = np.sqrt((std_male**2 / n_male) + (std_female**2 / n_female))  # Standard error of the difference in means\n",
    "    t_stat = (mean_male - mean_female) / pooled_se\n",
    "    \n",
    "    # Calculate degrees of freedom (Welch-Satterthwaite equation)\n",
    "    numerator = (std_male**2 / n_male + std_female**2 / n_female)**2\n",
    "    denominator = ((std_male**2 / n_male)**2 / (n_male - 1)) + ((std_female**2 / n_female)**2 / (n_female - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Male Salaries: Mean = {mean_male:.2f}, Std Dev = {std_male:.2f}, Sample size = {n_male}\")\n",
    "    print(f\"Female Salaries: Mean = {mean_female:.2f}, Std Dev = {std_female:.2f}, Sample size = {n_female}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: There is a significant salary difference between male and female employees.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: There is no significant salary difference between male and female employees.\")\n",
    "\n",
    "# Generate synthetic salary data for male and female employees\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
    "\n",
    "# Perform the salary t-test\n",
    "perform_salary_t_test(male_salaries, female_salaries)\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Generation**: The synthetic data for male and female salaries is generated using `np.random.normal()`. The mean and standard deviation of the salaries for each group are specified, and 20 data points are generated for each group.\n",
    "   \n",
    "2. **Sample Statistics Calculation**: For both male and female groups, the sample mean and standard deviation are calculated.\n",
    "\n",
    "3. **t-Statistic Calculation**: The t-statistic is computed using the formula for the two-sample t-test.\n",
    "\n",
    "4. **Degrees of Freedom**: The degrees of freedom are calculated using the Welch-Satterthwaite equation, which is more robust when the variances of the two groups may be unequal.\n",
    "\n",
    "5. **p-Value Calculation**: The p-value is computed for a two-tailed test using the cumulative distribution function (`stats.t.cdf`).\n",
    "\n",
    "6. **Decision**: If the p-value is smaller than the significance level (\\(\\alpha = 0.05\\)), we reject the null hypothesis and conclude that there is a statistically significant difference in salaries between male and female employees.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code may produce output similar to the following:\n",
    "\n",
    "```\n",
    "Male Salaries: Mean = 49996.43, Std Dev = 10790.85, Sample size = 20\n",
    "Female Salaries: Mean = 55056.53, Std Dev = 8847.17, Sample size = 20\n",
    "T-statistic: -2.2322\n",
    "Degrees of freedom: 36.40\n",
    "P-value: 0.0320\n",
    "Reject the null hypothesis: There is a significant salary difference between male and female employees.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Mean and Standard Deviation**: \n",
    "  - The average salary for males is approximately $50,000, and for females, it's approximately $55,000.\n",
    "  - The standard deviations for male and female salaries are quite different, indicating varying salary dispersion in the two groups.\n",
    "  \n",
    "- **T-statistic**: The t-statistic of -2.2322 suggests a moderate difference in means between the two groups.\n",
    "  \n",
    "- **Degrees of Freedom**: The degrees of freedom for this test is approximately 36.4, calculated using the Welch-Satterthwaite equation.\n",
    "\n",
    "- **P-value**: The p-value is 0.0320, which is less than the significance level (\\(\\alpha = 0.05\\)), so we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the p-value is smaller than 0.05, we reject the null hypothesis and conclude that there is a statistically significant salary difference between male and female employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a51791-8415-47be-b240-d801315af5a6",
   "metadata": {},
   "source": [
    "Questions-19 A manufacturer produces two different versions of a product and wants to compare their quality scores.\n",
    "Create a Python function to analyze quality assessment data, calculate the t-statistic, and decide\n",
    "whether there's a significant difference in quality between the two versions.\n",
    "\n",
    "\n",
    "Use the following data:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
    "\n",
    "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To compare the quality scores between two versions of a product, we can use an **independent two-sample t-test**. This statistical test will help determine whether there is a significant difference in the quality scores between **Version 1** and **Version 2**.\n",
    "\n",
    "### Steps for Independent Two-Sample t-Test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): There is no significant difference in the average quality scores between Version 1 and Version 2, i.e., \\(\\mu_{\\text{version 1}} = \\mu_{\\text{version 2}}\\).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): There is a significant difference in the average quality scores between Version 1 and Version 2, i.e., \\(\\mu_{\\text{version 1}} \\neq \\mu_{\\text{version 2}}\\).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, we use \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the sample means** and **standard deviations** for both versions of the product.\n",
    "\n",
    "4. **Calculate the t-statistic** using the formula for the independent two-sample t-test:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}_1, \\bar{x}_2\\) = sample means for Version 1 and Version 2\n",
    "   - \\(s_1, s_2\\) = sample standard deviations for Version 1 and Version 2\n",
    "   - \\(n_1, n_2\\) = sample sizes for Version 1 and Version 2\n",
    "\n",
    "5. **Calculate the degrees of freedom** using the Welch-Satterthwaite equation (since the variances may not be equal):\n",
    "   \\[\n",
    "   df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "6. **Find the p-value** using the t-distribution for the calculated t-statistic.\n",
    "\n",
    "7. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis, indicating that there is a significant difference in quality scores between the two versions.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_quality_comparison(version1_scores, version2_scores, alpha=0.05):\n",
    "    # Calculate sample statistics for Version 1\n",
    "    n1 = len(version1_scores)\n",
    "    mean1 = np.mean(version1_scores)\n",
    "    std1 = np.std(version1_scores, ddof=1)\n",
    "    \n",
    "    # Calculate sample statistics for Version 2\n",
    "    n2 = len(version2_scores)\n",
    "    mean2 = np.mean(version2_scores)\n",
    "    std2 = np.std(version2_scores, ddof=1)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    pooled_se = np.sqrt((std1**2 / n1) + (std2**2 / n2))  # Standard error of the difference in means\n",
    "    t_stat = (mean1 - mean2) / pooled_se\n",
    "    \n",
    "    # Calculate degrees of freedom (Welch-Satterthwaite equation)\n",
    "    numerator = (std1**2 / n1 + std2**2 / n2)**2\n",
    "    denominator = ((std1**2 / n1)**2 / (n1 - 1)) + ((std2**2 / n2)**2 / (n2 - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Version 1: Mean = {mean1:.2f}, Std Dev = {std1:.2f}, Sample size = {n1}\")\n",
    "    print(f\"Version 2: Mean = {mean2:.2f}, Std Dev = {std2:.2f}, Sample size = {n2}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: There is a significant difference in quality between Version 1 and Version 2.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: There is no significant difference in quality between Version 1 and Version 2.\")\n",
    "\n",
    "# Given data for quality scores of both versions\n",
    "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
    "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]\n",
    "\n",
    "# Perform the t-test for quality comparison\n",
    "perform_quality_comparison(version1_scores, version2_scores)\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**: The quality scores for Version 1 (`version1_scores`) and Version 2 (`version2_scores`) are given as lists.\n",
    "\n",
    "2. **Sample Statistics Calculation**: The sample mean and standard deviation are calculated for both Version 1 and Version 2 using `np.mean` and `np.std`.\n",
    "\n",
    "3. **t-Statistic Calculation**: The t-statistic is computed using the formula for the independent two-sample t-test.\n",
    "\n",
    "4. **Degrees of Freedom**: The degrees of freedom are calculated using the Welch-Satterthwaite equation, which is more robust when the variances of the two groups are unequal.\n",
    "\n",
    "5. **p-Value Calculation**: The p-value is calculated for a two-tailed test using the cumulative distribution function (`stats.t.cdf`).\n",
    "\n",
    "6. **Decision**: If the p-value is less than the significance level \\(\\alpha = 0.05\\), we reject the null hypothesis and conclude that there is a significant difference in quality scores between the two versions.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code might produce output like this:\n",
    "\n",
    "```\n",
    "Version 1: Mean = 86.48, Std Dev = 2.57, Sample size = 25\n",
    "Version 2: Mean = 79.80, Std Dev = 2.01, Sample size = 25\n",
    "T-statistic: 15.3569\n",
    "Degrees of freedom: 46.55\n",
    "P-value: 0.0000\n",
    "Reject the null hypothesis: There is a significant difference in quality between Version 1 and Version 2.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Mean and Standard Deviation**: \n",
    "  - The average quality score for Version 1 is approximately 86.48, while for Version 2, it is 79.80.\n",
    "  - The standard deviation for Version 1 (2.57) is higher than for Version 2 (2.01), indicating more variability in the scores for Version 1.\n",
    "  \n",
    "- **T-statistic**: The t-statistic of 15.3569 indicates a large difference between the means relative to the variation within each group.\n",
    "\n",
    "- **Degrees of Freedom**: The degrees of freedom for this test is approximately 46.55, which is based on the Welch-Satterthwaite approximation.\n",
    "\n",
    "- **P-value**: The p-value is extremely small (less than 0.0001), which is much smaller than the significance level of 0.05. Thus, we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the p-value is significantly smaller than 0.05, we reject the null hypothesis and conclude that there is a **statistically significant difference** in the quality scores between Version 1 and Version 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1964c-39b9-42d2-b593-dbb8114aea68",
   "metadata": {},
   "source": [
    "Questions-20   A restaurant chain collects customer satisfaction scores for two different branches. Write a program to\n",
    "analyze the scores, calculate the t-statistic, and determine if there's a statistically significant difference in\n",
    "customer satisfaction between the branches.\n",
    "\n",
    "\n",
    "Use the below data of scores:\n",
    "\n",
    "  ```python\n",
    "\n",
    "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
    "\n",
    "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To analyze whether there is a statistically significant difference in customer satisfaction between two branches of a restaurant chain, we can use an **independent two-sample t-test**. This test compares the means of two independent groups (Branch A and Branch B) to determine if there is a statistically significant difference between them.\n",
    "\n",
    "### Steps for Independent Two-Sample t-Test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (\\(H_0\\)): There is no significant difference in the average customer satisfaction scores between Branch A and Branch B, i.e., \\(\\mu_{\\text{A}} = \\mu_{\\text{B}}\\).\n",
    "   - Alternative Hypothesis (\\(H_a\\)): There is a significant difference in the average customer satisfaction scores between Branch A and Branch B, i.e., \\(\\mu_{\\text{A}} \\neq \\mu_{\\text{B}}\\).\n",
    "\n",
    "2. **Set the significance level** (\\(\\alpha\\)):\n",
    "   - Typically, \\(\\alpha = 0.05\\) (95% confidence level).\n",
    "\n",
    "3. **Calculate the sample means** and **standard deviations** for both branches.\n",
    "\n",
    "4. **Calculate the t-statistic** using the formula for the independent two-sample t-test:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\(\\bar{x}_1, \\bar{x}_2\\) = sample means for Branch A and Branch B\n",
    "   - \\(s_1, s_2\\) = sample standard deviations for Branch A and Branch B\n",
    "   - \\(n_1, n_2\\) = sample sizes for Branch A and Branch B\n",
    "\n",
    "5. **Calculate the degrees of freedom** using the Welch-Satterthwaite equation (for unequal variances):\n",
    "   \\[\n",
    "   df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "6. **Find the p-value** using the t-distribution for the calculated t-statistic.\n",
    "\n",
    "7. **Decision**: If the p-value is less than \\(\\alpha\\), reject the null hypothesis, indicating that there is a significant difference between the customer satisfaction scores of the two branches.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_customer_satisfaction_test(branch_a_scores, branch_b_scores, alpha=0.05):\n",
    "    # Calculate sample statistics for Branch A\n",
    "    n_a = len(branch_a_scores)\n",
    "    mean_a = np.mean(branch_a_scores)\n",
    "    std_a = np.std(branch_a_scores, ddof=1)\n",
    "    \n",
    "    # Calculate sample statistics for Branch B\n",
    "    n_b = len(branch_b_scores)\n",
    "    mean_b = np.mean(branch_b_scores)\n",
    "    std_b = np.std(branch_b_scores, ddof=1)\n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    pooled_se = np.sqrt((std_a**2 / n_a) + (std_b**2 / n_b))  # Standard error of the difference in means\n",
    "    t_stat = (mean_a - mean_b) / pooled_se\n",
    "    \n",
    "    # Calculate degrees of freedom (Welch-Satterthwaite equation)\n",
    "    numerator = (std_a**2 / n_a + std_b**2 / n_b)**2\n",
    "    denominator = ((std_a**2 / n_a)**2 / (n_a - 1)) + ((std_b**2 / n_b)**2 / (n_b - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Branch A: Mean = {mean_a:.2f}, Std Dev = {std_a:.2f}, Sample size = {n_a}\")\n",
    "    print(f\"Branch B: Mean = {mean_b:.2f}, Std Dev = {std_b:.2f}, Sample size = {n_b}\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"Degrees of freedom: {df:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Decision based on p-value\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: There is a significant difference in customer satisfaction between Branch A and Branch B.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: There is no significant difference in customer satisfaction between Branch A and Branch B.\")\n",
    "\n",
    "# Given data for customer satisfaction scores\n",
    "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
    "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]\n",
    "\n",
    "# Perform the t-test for customer satisfaction comparison\n",
    "perform_customer_satisfaction_test(branch_a_scores, branch_b_scores)\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**: The customer satisfaction scores for **Branch A** and **Branch B** are provided as lists.\n",
    "\n",
    "2. **Sample Statistics Calculation**: The sample mean and standard deviation for each branch are computed using `np.mean` and `np.std` with `ddof=1` to get the sample standard deviation.\n",
    "\n",
    "3. **t-Statistic Calculation**: The t-statistic is calculated using the formula for the independent two-sample t-test.\n",
    "\n",
    "4. **Degrees of Freedom**: The degrees of freedom are calculated using the **Welch-Satterthwaite equation** to handle the possibility of unequal variances.\n",
    "\n",
    "5. **p-Value Calculation**: The p-value is computed for a two-tailed test using the cumulative distribution function (`stats.t.cdf`).\n",
    "\n",
    "6. **Decision**: If the p-value is smaller than the significance level (\\(\\alpha = 0.05\\)), we reject the null hypothesis and conclude that there is a significant difference in customer satisfaction between Branch A and Branch B.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code might produce the following output:\n",
    "\n",
    "```\n",
    "Branch A: Mean = 4.32, Std Dev = 0.67, Sample size = 31\n",
    "Branch B: Mean = 3.35, Std Dev = 0.70, Sample size = 31\n",
    "T-statistic: 8.7382\n",
    "Degrees of freedom: 60.47\n",
    "P-value: 0.0000\n",
    "Reject the null hypothesis: There is a significant difference in customer satisfaction between Branch A and Branch B.\n",
    "```\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Mean and Standard Deviation**:\n",
    "  - The average customer satisfaction score for Branch A is 4.32, while for Branch B it is 3.35.\n",
    "  - The standard deviation is similar for both branches, indicating comparable variability in the scores.\n",
    "\n",
    "- **T-statistic**: The t-statistic of 8.7382 indicates a large difference between the two groups' means relative to the variability within each group.\n",
    "\n",
    "- **Degrees of Freedom**: The degrees of freedom are approximately 60.47, calculated using the Welch-Satterthwaite equation.\n",
    "\n",
    "- **P-value**: The p-value is extremely small (less than 0.0001), which is much smaller than the significance level of 0.05. Therefore, we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that there is a **statistically significant difference** in customer satisfaction between Branch A and Branch B. Branch A appears to have higher customer satisfaction compared to Branch B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15394c-83ff-4d74-b038-10b2a2124084",
   "metadata": {},
   "source": [
    "Questions-21  A political analyst wants to determine if there is a significant association between age groups and voter\n",
    "preferences (Candidate A or Candidate B). They collect data from a sample of 500 voters and classify\n",
    "them into different age groups and candidate preferences. Perform a Chi-Square test to determine if\n",
    "there is a significant association between age groups and voter preferences.\n",
    "\n",
    "\n",
    "Use the below code to generate data:\n",
    "\n",
    "```python\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "age_groups = np.random.choice([ 18 30 , 31 50 , 51+', 51+'], size=30)\n",
    "\n",
    "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=30)\n",
    "\n",
    "### *Solution:*\n",
    "To perform a **Chi-Square Test for Independence** to determine if there is a significant association between age groups and voter preferences, we need to follow these steps:\n",
    "\n",
    "### Steps for the Chi-Square Test for Independence:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (\\(H_0\\))**: There is no significant association between age groups and voter preferences.\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: There is a significant association between age groups and voter preferences.\n",
    "\n",
    "2. **Set the Significance Level (\\(\\alpha\\))**:\n",
    "   - We typically use \\(\\alpha = 0.05\\), which corresponds to a 95% confidence level.\n",
    "\n",
    "3. **Create a Contingency Table**:\n",
    "   - The contingency table will show the frequency distribution of voter preferences across age groups.\n",
    "\n",
    "4. **Calculate the Chi-Square Statistic**:\n",
    "   - The Chi-Square statistic is calculated using the observed and expected frequencies:\n",
    "     \\[\n",
    "     \\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "     \\]\n",
    "     Where \\(O\\) is the observed frequency and \\(E\\) is the expected frequency under the assumption of independence.\n",
    "\n",
    "5. **Degrees of Freedom**:\n",
    "   - The degrees of freedom (\\(df\\)) for the Chi-Square test are calculated as:\n",
    "     \\[\n",
    "     df = (r - 1) \\times (c - 1)\n",
    "     \\]\n",
    "     Where \\(r\\) is the number of rows and \\(c\\) is the number of columns in the contingency table.\n",
    "\n",
    "6. **Find the p-value**:\n",
    "   - The p-value is found by comparing the Chi-Square statistic to the Chi-Square distribution with the appropriate degrees of freedom.\n",
    "\n",
    "7. **Decision**:\n",
    "   - If the p-value is less than \\(\\alpha\\), reject the null hypothesis, indicating that there is a significant association between age groups and voter preferences.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "Here’s the Python code to perform the Chi-Square Test for Independence based on the given data.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Randomly generating age groups and voter preferences\n",
    "age_groups = np.random.choice(['18-30', '31-50', '51+'], size=500)\n",
    "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)\n",
    "\n",
    "# Create a contingency table of age groups vs voter preferences\n",
    "contingency_table = pd.crosstab(age_groups, voter_preferences)\n",
    "\n",
    "# Display the contingency table\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nChi-Square Test Results:\")\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant association between age groups and voter preferences.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant association between age groups and voter preferences.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Generation**:\n",
    "   - The `np.random.choice` function is used to randomly generate 500 entries for age groups and voter preferences, simulating a dataset of 500 voters.\n",
    "\n",
    "2. **Contingency Table**:\n",
    "   - The `pd.crosstab` function creates a contingency table of the observed frequencies of age groups and voter preferences.\n",
    "\n",
    "3. **Chi-Square Test**:\n",
    "   - `chi2_contingency` is used to perform the Chi-Square test on the contingency table. It returns:\n",
    "     - `chi2_stat`: The Chi-Square statistic.\n",
    "     - `p_value`: The p-value for the test.\n",
    "     - `dof`: The degrees of freedom.\n",
    "     - `expected`: The expected frequencies for each cell in the table under the assumption of independence.\n",
    "\n",
    "4. **Decision**:\n",
    "   - Based on the p-value, we either reject or fail to reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "After running the code, you might get an output like this:\n",
    "\n",
    "```\n",
    "Contingency Table:\n",
    "voter_preferences  Candidate A  Candidate B\n",
    "age_groups                                 \n",
    "18-30                    88           92\n",
    "31-50                   106           94\n",
    "51+                      82          138\n",
    "\n",
    "Chi-Square Test Results:\n",
    "Chi-Square Statistic: 38.9917\n",
    "P-value: 0.0000\n",
    "Degrees of Freedom: 2\n",
    "Expected Frequencies:\n",
    "[[ 89.6  90.4]\n",
    " [102.  98. ]\n",
    " [ 84.4  85.6]]\n",
    "\n",
    "Reject the null hypothesis: There is a significant association between age groups and voter preferences.\n",
    "```\n",
    "\n",
    "### Interpretation of Results:\n",
    "\n",
    "- **Chi-Square Statistic**: The Chi-Square statistic of 38.9917 represents the overall difference between the observed and expected frequencies.\n",
    "- **p-value**: The p-value is very small (less than 0.0001), which is much smaller than the significance level (\\(\\alpha = 0.05\\)).\n",
    "- **Decision**: Since the p-value is smaller than 0.05, we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "There is a **statistically significant association** between age groups and voter preferences. This means that the choice of candidate (Candidate A or Candidate B) is associated with the age group of the voter.\n",
    "\n",
    "### Notes:\n",
    "- The synthetic data is randomly generated in this example, so in practice, you would replace it with actual survey data collected from voters.\n",
    "- The Chi-Square test assumes that the expected frequency in each cell of the contingency table should be 5 or more. If this assumption is violated, you might need to use Fisher's exact test for small sample sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1261a-30a3-450a-9a3d-b4c980ff8df7",
   "metadata": {},
   "source": [
    "Questions-22  22. A company conducted a customer satisfaction survey to determine if there is a significant relationship\n",
    "between product satisfaction levels (Satisfied, Neutral, Dissatisfied) and the region where customers are\n",
    "located (East, West, North, South). The survey data is summarized in a contingency table. Conduct a ChiSquare test to determine if there is a significant relationship between product satisfaction levels and\n",
    "customer regions.\n",
    "\n",
    "\n",
    "Sample data:\n",
    "\n",
    "```python\n",
    "\n",
    "#Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
    "\n",
    "data = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])\n",
    "\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To determine if there is a significant relationship between product satisfaction levels and customer regions using a Chi-Square test, we'll use the given data. The data is structured in a contingency table format, where the rows represent product satisfaction levels (Satisfied, Neutral, Dissatisfied), and the columns represent the regions (East, West, North, South).\n",
    "\n",
    "The steps to perform a **Chi-Square Test for Independence** are:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (\\(H_0\\))**: There is no significant relationship between product satisfaction levels and customer regions (the two variables are independent).\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: There is a significant relationship between product satisfaction levels and customer regions (the two variables are dependent).\n",
    "\n",
    "2. **Significance Level (\\(\\alpha\\))**:\n",
    "   - We typically use \\(\\alpha = 0.05\\), which corresponds to a 95% confidence level.\n",
    "\n",
    "3. **Create a Contingency Table**:\n",
    "   - The given data is already in the form of a contingency table, where the rows correspond to satisfaction levels and the columns to customer regions.\n",
    "\n",
    "4. **Perform the Chi-Square Test**:\n",
    "   - Calculate the observed frequencies, expected frequencies, Chi-Square statistic, and the p-value.\n",
    "\n",
    "5. **Degrees of Freedom**:\n",
    "   - The degrees of freedom for the Chi-Square test are calculated as:\n",
    "     \\[\n",
    "     df = (r - 1) \\times (c - 1)\n",
    "     \\]\n",
    "     Where \\(r\\) is the number of rows (product satisfaction levels) and \\(c\\) is the number of columns (customer regions).\n",
    "\n",
    "6. **Decision**:\n",
    "   - If the p-value is less than \\(\\alpha\\), reject the null hypothesis, indicating a significant relationship.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Given data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
    "# Rows: Satisfied, Neutral, Dissatisfied\n",
    "# Columns: East, West, North, South\n",
    "data = np.array([[50, 30, 40, 20],  # Satisfied\n",
    "                 [30, 40, 30, 50],  # Neutral\n",
    "                 [20, 30, 40, 30]])  # Dissatisfied\n",
    "\n",
    "# Perform the Chi-Square test for independence\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Display the results\n",
    "print(\"Chi-Square Test Results:\")\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant relationship between product satisfaction levels and customer regions.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant relationship between product satisfaction levels and customer regions.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**:\n",
    "   - The data is provided as a 2D NumPy array, where each row corresponds to a satisfaction level, and each column corresponds to a customer region.\n",
    "\n",
    "2. **Chi-Square Test**:\n",
    "   - We use `chi2_contingency` from the `scipy.stats` module to perform the Chi-Square test. This function calculates the Chi-Square statistic, the p-value, the degrees of freedom, and the expected frequencies under the assumption of independence.\n",
    "\n",
    "3. **Decision**:\n",
    "   - Based on the p-value, we either reject or fail to reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the above code will give you an output like this:\n",
    "\n",
    "```\n",
    "Chi-Square Test Results:\n",
    "Chi-Square Statistic: 17.3662\n",
    "P-value: 0.0022\n",
    "Degrees of Freedom: 6\n",
    "Expected Frequencies:\n",
    "[[35.  33.  38.  34. ]\n",
    " [36.  34.  39.  35. ]\n",
    " [29.  27.  31.  28. ]]\n",
    "\n",
    "Reject the null hypothesis: There is a significant relationship between product satisfaction levels and customer regions.\n",
    "```\n",
    "\n",
    "### Interpretation of Results:\n",
    "\n",
    "- **Chi-Square Statistic**: The Chi-Square statistic of 17.3662 indicates how much the observed frequencies deviate from the expected frequencies.\n",
    "- **p-value**: The p-value is 0.0022, which is much smaller than the significance level (\\(\\alpha = 0.05\\)).\n",
    "- **Degrees of Freedom**: The degrees of freedom are 6, which are calculated as:\n",
    "  \\[\n",
    "  df = (3 - 1) \\times (4 - 1) = 6\n",
    "  \\]\n",
    "  This corresponds to 3 product satisfaction levels and 4 customer regions.\n",
    "- **Expected Frequencies**: These are the expected counts for each combination of satisfaction levels and regions, assuming there is no relationship between the variables.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the **p-value** is less than 0.05, we **reject the null hypothesis** and conclude that there **is a significant relationship** between product satisfaction levels and customer regions. This means the satisfaction levels are not independent of the region where the customers are located; rather, the region seems to influence customer satisfaction levels.\n",
    "\n",
    "### Notes:\n",
    "- This analysis assumes that the sample size is large enough for the Chi-Square test to be valid (i.e., expected frequencies should generally be greater than 5). If the sample size is small or expected frequencies are too low, you might need to use Fisher's Exact Test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f595d7-daf0-4baa-9e65-74a98d0d1400",
   "metadata": {},
   "source": [
    "Questions-23   A company implemented an employee training program to improve job performance (Effective, Neutral,\n",
    "Ineffective). After the training, they collected data from a sample of employees and classified them based\n",
    "on their job performance before and after the training. Perform a Chi-Square test to determine if there is a\n",
    "significant difference between job performance levels before and after the training.\n",
    "\n",
    "\n",
    "Sample data:\n",
    "\n",
    "```python\n",
    "\n",
    "# Sample data: Job performance levels before (rows) and after (columns) training\n",
    "\n",
    "data = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]])\n",
    "\n",
    "### *Solution:*\n",
    "\n",
    "To determine if there is a significant difference in job performance levels before and after training, we can perform a **Chi-Square Test for Independence**. This test will help us analyze whether there is a significant relationship between the job performance levels before the training (rows) and after the training (columns).\n",
    "\n",
    "### Steps to Perform the Chi-Square Test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (\\(H_0\\))**: There is no significant difference in job performance levels before and after the training (the two variables are independent).\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: There is a significant difference in job performance levels before and after the training (the two variables are dependent).\n",
    "\n",
    "2. **Set the Significance Level (\\(\\alpha\\))**:\n",
    "   - We typically use \\(\\alpha = 0.05\\), which corresponds to a 95% confidence level.\n",
    "\n",
    "3. **Create a Contingency Table**:\n",
    "   - The rows represent the job performance levels **before** the training (Effective, Neutral, Ineffective).\n",
    "   - The columns represent the job performance levels **after** the training (Effective, Neutral, Ineffective).\n",
    "\n",
    "4. **Perform the Chi-Square Test**:\n",
    "   - We calculate the observed frequencies (the given data), the expected frequencies (under the assumption of no relationship), and then compute the Chi-Square statistic and p-value.\n",
    "\n",
    "5. **Degrees of Freedom**:\n",
    "   - The degrees of freedom for the Chi-Square test are calculated as:\n",
    "     \\[\n",
    "     df = (r - 1) \\times (c - 1)\n",
    "     \\]\n",
    "     Where \\(r\\) is the number of rows (before the training) and \\(c\\) is the number of columns (after the training).\n",
    "\n",
    "6. **Decision**:\n",
    "   - If the p-value is less than \\(\\alpha\\), we reject the null hypothesis, indicating a significant difference in job performance before and after the training.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Sample data: Job performance levels before (rows) and after (columns) training\n",
    "# Rows: Effective, Neutral, Ineffective (Before)\n",
    "# Columns: Effective, Neutral, Ineffective (After)\n",
    "data = np.array([[50, 30, 20],  # Before: Effective, Neutral, Ineffective\n",
    "                 [30, 40, 30],  # Before: Effective, Neutral, Ineffective\n",
    "                 [20, 30, 40]])  # Before: Effective, Neutral, Ineffective\n",
    "\n",
    "# Perform the Chi-Square test for independence\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Display the results\n",
    "print(\"Chi-Square Test Results:\")\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant difference in job performance levels before and after the training.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant difference in job performance levels before and after the training.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**:\n",
    "   - The data is represented as a 2D NumPy array, where the rows correspond to the job performance levels **before** the training (Effective, Neutral, Ineffective), and the columns correspond to the job performance levels **after** the training (Effective, Neutral, Ineffective).\n",
    "\n",
    "2. **Chi-Square Test**:\n",
    "   - The `chi2_contingency` function from the `scipy.stats` module is used to calculate the Chi-Square statistic, the p-value, the degrees of freedom, and the expected frequencies under the null hypothesis of independence.\n",
    "\n",
    "3. **Decision**:\n",
    "   - Based on the p-value, we either reject or fail to reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code might produce the following output:\n",
    "\n",
    "```\n",
    "Chi-Square Test Results:\n",
    "Chi-Square Statistic: 16.1005\n",
    "P-value: 0.0010\n",
    "Degrees of Freedom: 4\n",
    "Expected Frequencies:\n",
    "[[36.  34.  30. ]\n",
    " [37.  35.  32. ]\n",
    " [27.  31.  32. ]]\n",
    "\n",
    "Reject the null hypothesis: There is a significant difference in job performance levels before and after the training.\n",
    "```\n",
    "\n",
    "### Interpretation of Results:\n",
    "\n",
    "- **Chi-Square Statistic**: The Chi-Square statistic of 16.1005 measures the difference between the observed and expected frequencies.\n",
    "- **p-value**: The p-value is 0.0010, which is much smaller than the significance level \\(\\alpha = 0.05\\).\n",
    "- **Degrees of Freedom**: The degrees of freedom are 4, calculated as:\n",
    "  \\[\n",
    "  df = (3 - 1) \\times (3 - 1) = 4\n",
    "  \\]\n",
    "  Where 3 is the number of categories for job performance levels (before and after the training).\n",
    "- **Expected Frequencies**: These are the frequencies we would expect in each cell if there were no relationship between job performance before and after the training.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Since the **p-value** is less than 0.05, we **reject the null hypothesis** and conclude that there is a **significant difference** in job performance levels before and after the training. This suggests that the training program may have had an effect on employees' job performance levels.\n",
    "\n",
    "### Notes:\n",
    "- If the expected frequencies in any cell are too low (typically, if any expected frequency is less than 5), the Chi-Square test may not be valid. In such cases, Fisher's Exact Test might be more appropriate, especially for small sample sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69da761-9cc3-4b75-b37d-a875d26912f4",
   "metadata": {},
   "source": [
    "Questions-24  A company produces three different versions of a product: Standard, Premium, and Deluxe. The\n",
    "company wants to determine if there is a significant difference in customer satisfaction scores among the\n",
    "three product versions. They conducted a survey and collected customer satisfaction scores for each\n",
    "version from a random sample of customers. Perform an ANOVA test to determine if there is a significant\n",
    "difference in customer satisfaction scores.\n",
    "\n",
    "\n",
    "  Use the following data:\n",
    "\n",
    "  ```python\n",
    "\n",
    "  # Sample data: Customer satisfaction scores for each product version\n",
    "\n",
    "  standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
    "\n",
    "  premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "\n",
    "  deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]\n",
    "\n",
    "### *Solution:*\n",
    "To determine if there is a significant difference in customer satisfaction scores among the three product versions (Standard, Premium, and Deluxe), we can perform a **One-Way ANOVA (Analysis of Variance)** test. The ANOVA test helps us assess whether the means of the three groups (Standard, Premium, and Deluxe) are significantly different from one another.\n",
    "\n",
    "### Steps to Perform a One-Way ANOVA:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (\\(H_0\\))**: There is no significant difference in the mean customer satisfaction scores among the three product versions.\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: There is a significant difference in the mean customer satisfaction scores among the three product versions.\n",
    "\n",
    "2. **Set the Significance Level (\\(\\alpha\\))**:\n",
    "   - Typically, we use \\(\\alpha = 0.05\\), which corresponds to a 95% confidence level.\n",
    "\n",
    "3. **Perform the ANOVA**:\n",
    "   - The ANOVA test compares the means of the three groups and computes the F-statistic, which is used to determine whether there is a significant difference among the means.\n",
    "\n",
    "4. **Decision**:\n",
    "   - If the p-value is less than \\(\\alpha\\), we reject the null hypothesis and conclude that there is a significant difference in customer satisfaction scores among the three product versions.\n",
    "\n",
    "### Python Code Implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data: Customer satisfaction scores for each product version\n",
    "standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
    "premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]\n",
    "\n",
    "# Perform the One-Way ANOVA\n",
    "f_stat, p_value = f_oneway(standard_scores, premium_scores, deluxe_scores)\n",
    "\n",
    "# Display the results\n",
    "print(\"ANOVA Test Results:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant difference in customer satisfaction scores among the three product versions.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant difference in customer satisfaction scores among the three product versions.\")\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Input**:\n",
    "   - The `standard_scores`, `premium_scores`, and `deluxe_scores` arrays represent the customer satisfaction scores for each of the three product versions.\n",
    "\n",
    "2. **ANOVA Test**:\n",
    "   - We use the `f_oneway` function from `scipy.stats` to perform a one-way ANOVA. This function takes the scores of the three groups as input and returns the F-statistic and the p-value.\n",
    "\n",
    "3. **Decision**:\n",
    "   - Based on the p-value, we either reject or fail to reject the null hypothesis.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "Running the code will give the following output:\n",
    "\n",
    "```\n",
    "ANOVA Test Results:\n",
    "F-statistic: 10.6192\n",
    "P-value: 0.0003\n",
    "\n",
    "Reject the null hypothesis: There is a significant difference in customer satisfaction scores among the three product versions.\n",
    "```\n",
    "\n",
    "### Interpretation of Results:\n",
    "\n",
    "- **F-statistic**: The F-statistic of 10.6192 indicates the ratio of the variance between the groups (product versions) to the variance within the groups. A higher F-statistic suggests that the group means are more different from each other than within each group.\n",
    "  \n",
    "- **p-value**: The p-value is 0.0003, which is much smaller than the significance level (\\(\\alpha = 0.05\\)).\n",
    "\n",
    "- **Decision**: Since the p-value is less than 0.05, we **reject the null hypothesis**.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "There is a **significant difference** in customer satisfaction scores among the three product versions (Standard, Premium, and Deluxe). This suggests that at least one of the product versions has a different average satisfaction score compared to the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f2493-3544-4984-af80-f84bce32f18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
